#!/usr/bin/env perl
use strict;
use warnings;

=head1 AUTHOR

Sendu Bala <sb10@sanger.ac.uk>.

=head1 COPYRIGHT AND LICENSE

Copyright (c) 2012-2014 Genome Research Limited.

This file is part of VRPipe.

VRPipe is free software: you can redistribute it and/or modify it under the
terms of the GNU General Public License as published by the Free Software
Foundation, either version 3 of the License, or (at your option) any later
version.

This program is distributed in the hope that it will be useful, but WITHOUT ANY
WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A
PARTICULAR PURPOSE. See the GNU General Public License for more details.

You should have received a copy of the GNU General Public License along with
this program. If not, see L<http://www.gnu.org/licenses/>.

=cut

use EV;
use AnyEvent;
use AnyEvent::Util qw(fork_call);
use VRPipe::Interface::CmdLine;
use VRPipe::Interface::BackEnd;
use Sys::CPU;
use POSIX qw(floor ceil);
use List::Util 'shuffle';
use Path::Class;
use Cwd 'getcwd';
use Digest::MD5;
use VRPipe::Persistent::InMemory;
use VRPipe::Persistent::Graph;
use VRPipe::Schema;
use File::Share ':all';
use Module::Find;
use DateTime;
use Authen::Simple::PAM;

# handle options
my $cmdline = VRPipe::Interface::CmdLine->new(
    description => "Control the VRPipe server, which provides the web and cmdline interfaces and keeps the pipeline system itself running by submitting things to the scheduler.",
    extra_args  => 'start|stop|restart|status',
    opt_spec    => [
        ['foreground|f',          'Do not daemonize - the server will run in the foreground, logging to STDERR'],
        ['farm=s',                'Discover and dispatch submissions to the job scheduler identified by the supplied name (only 1 server can dispatch to each farm)'],
        ['max_submissions|m=i',   'The maximum number of submissions to dispatch to the farm when in --farm mode (default is unlimited)'],
        ['only_specified_setups', 'In --farm mode, normally any PipelineSetups that have no farm configured will be run on a random farm, so potentially via this server; turning this option on means this server will only handle setups configured for this farm'],
        [],
        ['debug', 'turn lots of debugging output on']
    ]
);

my $backend;
my $deployment            = $cmdline->opts('deployment');
my $foreground            = $cmdline->opts('foreground');
my $farm                  = $cmdline->opts('farm');
my $max_subs              = $cmdline->opts('max_submissions');
my $only_specified_setups = $cmdline->opts('only_specified_setups') || 0;
my $debug                 = $cmdline->opts('debug');
my $scheduler;
my $im        = VRPipe::Persistent::InMemory->new();
my $dist_dir  = dir(dist_dir('VRPipe'))->absolute;
my $pages_dir = dir($dist_dir, 'pages');
my @pages;

while (my $sub_dir = $pages_dir->next) {
    next unless -d $sub_dir;
    my $index = file($sub_dir, 'index.html');
    next unless -e $index;
    push(@pages, $sub_dir->basename);
}
my $pages   = [sort @pages];
my %pages   = map { $_ => 1 } @pages;
my $graph   = VRPipe::Persistent::Graph->new(throw_with_no_stacktrace => 1);
my $vrtrack = VRPipe::Schema->create('VRTrack');

my $command = shift;
unless ($command) {
    $cmdline->error("a command is required");
    $cmdline->help;
}

# act on the given command
my $status = $cmdline->check_server(1);
my (undef, $port, $url) = @{ $cmdline->_ua_port_baseurl };
my $exit = 0;
if ($command eq 'status') {
    if ($status == 1) {
        $cmdline->output("VRPipe $deployment server is running at $url");
    }
    elsif ($status == 0) {
        $cmdline->output("VRPipe $deployment server is not running");
    }
    elsif ($status == -1) {
        $cmdline->output("A server is listening on port $port, but is not responding like our own VRPipe $deployment server would");
    }
}
elsif ($command eq 'stop') {
    my $stopped = stop();
    $exit = !$stopped;
}
elsif ($command eq 'start') {
    my $started = start();
    $exit = !$started;
}
elsif ($command eq 'restart') {
    $cmdline->output("Restarting VRPipe $deployment server...");
    my $stopped = stop();
    my $started = 0;
    if ($stopped) {
        my $started = start();
    }
    $exit = !$started;
}
else {
    $cmdline->die_with_error("$command is an invalid command");
}

exit $exit;

sub stop {
    if ($status == 1) {
        my $response = $cmdline->server_get('/stop');
        if ($response eq 'Stopping server') {
            # the server responded that it would stop; give it up to 5 seconds
            # to actually do that
            my $seconds = 5;
            while ($seconds--) {
                $status = $cmdline->check_server(1);
                last if $status == 0;
                sleep(1);
            }
            
            if ($status == 0) {
                $cmdline->output("VRPipe $deployment server was stopped");
                return 1;
            }
            else {
                $cmdline->output("VRPipe $deployment server claimed it would stop, but it still seems to be running");
                return 0;
            }
        }
        else {
            $cmdline->output("Failed to stop VRPipe $deployment server (it responded: '$response')");
            return 0;
        }
    }
    elsif ($status == 0) {
        $cmdline->output("VRPipe $deployment server was not running");
        return 1;
    }
    elsif ($status == -1) {
        $cmdline->output("Will not attempt to stop the VRPipe $deployment server listening on port $port, since it does not seem to be ours");
        return 0;
    }
}

sub start {
    if ($status == 1) {
        $cmdline->output("VRPipe $deployment server is already running");
        return 1;
    }
    elsif ($status == 0) {
        $cmdline->output("Will start VRPipe $deployment server at $url");
        start_server();
    }
    elsif ($status == -1) {
        $cmdline->output("Will not attempt to start the VRPipe $deployment server, since another incompatible server is already listening on port $port");
        return 0;
    }
}

sub start_server {
    # initialize the VRPipe backend
    $backend = VRPipe::Interface::BackEnd->new(deployment => $deployment, $farm ? (farm => $farm) : ());
    my $dtf = $backend->schema->storage->datetime_parser;
    if ($debug || $deployment eq 'testing') {
        $backend->set_verbose_global(1);
    }
    
    # daemonize unless we're not supposed to
    my $cwd = getcwd();
    $backend->daemonize unless $foreground;
    
    $AnyEvent::Util::MAX_FORKS = Sys::CPU::cpu_count();
    my $timer_interval = $deployment eq 'production' ? 30 : 5;
    my $inter_message_time = 3600;
    
    my $watcher_error_sub = sub {
        my $err = $@ || return;
        
        # when testing, we likely start the server and call some database-
        # requiring method before the VRPipe database has been created,
        # so we make a nicer error message
        if (ref($err)) {
            $err = "$err"; # try and stringify it
        }
        my $email_admin = 1;
        if ($err =~ /no such table/) {
            $err         = 'VRPipe database not created yet, cannot do all functions';
            $email_admin = 0;
        }
        
        # only log the same error message once per hour
        # try and make the 'same' error message that differs only by
        # references in stack traces literally the same
        my $standardised_error = $err;
        $standardised_error =~ s/(SCALAR|ARRAY|HASH|CODE|REF)\([^\)]+\)/$1()/g;
        
        # get the md5 checksum of the message to use as a key name for
        # a redis lock
        my $dmd5 = Digest::MD5->new();
        $dmd5->add($standardised_error);
        my $checksum = $dmd5->hexdigest;
        
        # do not log if we can't get a lock
        unless ($im->lock($checksum, unlock_after => $inter_message_time)) {
            return;
        }
        
        $im->log($err, email_admin => $email_admin);
    };
    
    # set up a timer that will write out stderr (which includes logs) to the log
    # file. (we do this because writing to a single file from thousands of
    # processes can cripple performance, so instead our single server process
    # does all the writing without slowing down anything else)
    my $err_watcher;
    my $im_stderr_output_sub;
    unless ($foreground) {
        my $working = 0;
        $im_stderr_output_sub = sub {
            return if $working;
            $working = 1;
            fork_call {
                $im->write_stderr;
                return;
            }
            sub { $working = 0; };
        };
        $err_watcher = EV::timer 0, $timer_interval, $im_stderr_output_sub;
    }
    
    # (for timers we use periodic instead of timer because timer seems to have
    # some bug where on the first invocation it happens twice at ~the same time,
    # which can be terrible for us. periodic (usually) does not)
    
    # set up the submission management system if we're supposed to
    my ($farm_server, $farm_watcher, $handler_path, $still_working, $scheduler_watcher);
    my $fork_alarm_time = $deployment eq 'production' ? 3600 : 900;
    if ($farm) {
        # every 30s we'll update which PipelineSetups we'll handle, and also
        # submit handlers to the farm and assign submissions to those handlers
        $farm_watcher = EV::periodic 0, $timer_interval, 0, sub {
            return if $still_working;
            $still_working = 1;
            
            unless ($farm_server) {
                # ideally we only want to be in this if ($farm) section if we
                # have managed to register_farm_server(), but we can only do
                # that once the database is ready, which won't be the case
                # whilst testing. So we use our timer to keep trying to get the
                # farm_server whilst it fails due to database issues, but cancel
                # the timer if we fail because another server is handling this
                # farm
                eval { $farm_server = $backend->register_farm_server($farm, only_ours => $only_specified_setups) };
                if ($@) {
                    &{$watcher_error_sub};
                }
                elsif ($farm_server) {
                    # our database must be ready now, so load all Pipeline and
                    # Step .pm modules into db if we haven't already. we do this
                    # async since if it takes too long the farm_server will
                    # think it died and we'll immediately lose it!
                    unless ($deployment eq 'testing') {
                        fork_call {
                            $backend->install_pipelines_and_steps;
                            
                            # also add or update all graph database schemas
                            foreach my $module (findallmod(VRPipe::Schema)) {
                                eval "require $module;";
                                unless ($@) {
                                    my ($type) = $module =~ /VRPipe::Schema::(\w+)/;
                                    $type || next;
                                    VRPipe::Schema->create($type, update_schemas_in_db => 1);
                                }
                            }
                            
                            return;
                        }
                        $watcher_error_sub;
                    }
                    
                    $im->log("Submission management started for farm $farm");
                    $handler_path = $cmdline->vrpipe_script_command('vrpipe-handler', $deployment);
                    $handler_path =~ s/^\S+perl/perl/; # different nodes may have different perls installed at different locations
                    $scheduler = VRPipe::Scheduler->create();
                    $scheduler->initialize_for_server;
                    
                    # some schedulers may need to do something periodically;
                    # set up a watcher for that now
                    my $sch_periodic_method = $scheduler->periodic_method;
                    if ($sch_periodic_method) {
                        my $working            = 0;
                        my $scheduler_interval = $timer_interval * 10;
                        $scheduler_watcher = EV::timer 0, $scheduler_interval, sub {
                            return if $working;
                            $working = 1;
                            fork_call {
                                return $scheduler->scheduler_instance->$sch_periodic_method(deployment => $deployment);
                            }
                            sub {
                                if (@_ && $scheduler->scheduler_instance->can($_[0])) {
                                    my ($method, @args) = @_;
                                    $scheduler->scheduler_instance->$method(@args);
                                }
                                $working = 0;
                                $@ || return;
                                &{$watcher_error_sub};
                            };
                        };
                    }
                    # make sure the redis server is alive
                    my $ok = $im->datastore_ok;
                    unless ($ok) {
                        $im->log("Can't continue submission management because I can't connect to the in-memory datastore");
                        $farm_server->unlock;
                        $farm_server->delete;
                        undef $farm_server;
                    }
                }
                else {
                    $im->log("Could not start submission management for farm $farm because some other server process is (or was recently) doing that");
                    undef $farm_server;
                }
                $still_working = 0;
            }
            else {
                my $still_locked = $farm_server->locked(by_me => 1);
                
                fork_call {
                    # this fork_call should not take that long, but it is
                    # critical that it not get stuck, or the server will seem to
                    # still be running fine yet won't be submitting any jobs. So
                    # we set up an alarm to kill it after a while
                    local $SIG{ALRM} = sub { die "Taking suspiciously long to ensure that the handlers are running; is the VRPipe database running OK, and is the job scheduler responsive?\n" };
                    alarm $fork_alarm_time;
                    
                    # check we're still valid
                    die "farmserver ", $farm_server->id, " is no longer locked\n" unless $still_locked;
                    my $in_db = $farm_server->search({ id => $farm_server->id });
                    die "farmserver ", $farm_server->id, " is no longer in the database\n" unless $in_db;
                    
                    # claim our setups
                    my @setups = grep { $deployment eq 'testing' ? !$_->currently_complete : 1 } $farm_server->claim_setups;
                    
                    if (@setups) {
                        # make sure the redis server is alive
                        my $ok = $im->datastore_ok;
                        unless ($ok) {
                            $im->log("Can't continue submission management because I can't connect to the in-memory datastore");
                            undef $farm_server;
                            return;
                        }
                        
                        # make sure we have a setups handler running for our
                        # farm. since our setups handler will run on a node
                        # and needs access to the t directory when testing, we
                        # will cd to the git root first for scheduler that need
                        # to
                        my $shcmd = "$handler_path --mode setups --farm $farm";
                        $scheduler->ensure_running(
                            cmd => $shcmd,
                            $deployment eq 'testing' ? (cwd => $cwd) : (),
                            requirements => VRPipe::Requirements->create(memory => 2900, time => 3600)
                        );
                        
                        # make sure we have sufficient submission handlers
                        # running...
                        
                        # get the count of requirements. Sadly we can't do a
                        # quick cursor->all because we need to take into account
                        # step limits. Also, to avoid handlers running a slow,
                        # complex query and possibly hitting transaction lock/
                        # database update inconsistency issues, instead of them
                        # selecting a Submission with normal db query they will
                        # get one from the redis queue we will make
                        my %already_taken;
                        my $req_to_subs = VRPipe::SidToSub->get_column_values(['req_id', 'sub_id'], { farm => $farm, sub_id => { '!=' => undef } });
                        foreach my $ref (@$req_to_subs) {
                            my ($req_id, $sub_id) = @$ref;
                            $already_taken{$req_id}->{$sub_id} = 1;
                        }
                        # (we have this in case the redis server goes down and
                        #  we lose that knowledge of what was grabbed)
                        
                        my $sched_id = $scheduler->id;
                        my $sub_pager = VRPipe::Submission->search_paged({ '_done' => 0, -or => [-and => ['_failed' => 1, retries => { '<' => 3 }], '_failed' => 0], scheduler => $sched_id, 'pipelinesetup.controlling_farm' => $farm, 'pipelinesetup.active' => 1, 'dataelement.withdrawn' => 0 }, { join => { stepstate => ['pipelinesetup', 'dataelement'] }, prefetch => ['requirements', 'job', { stepstate => { stepmember => 'step' } }] });
                        
                        my (%req_counts, %step_limits, %step_counts, %completed_setups, %redis_queue);
                        while (my $subs = $sub_pager->next(no_resetting => 1)) {
                            foreach my $sub (@$subs) {
                                my $sub_id = $sub->id;
                                my $req    = $sub->requirements;
                                my $req_id = $req->id;
                                
                                # delay looking at subs with this req_id while
                                # handler's are in the process of generating
                                # new subs with this req_id; this way we're more
                                # likely to get single large arrays for greater
                                # efficiency
                                next if $req->noted('generating_subs');
                                
                                # if the job is a block_and_skip_if_ok job, we
                                # don't actually block because of race condition
                                # issues, and because of fail and restart
                                # issues. Instead we always only actually queue
                                # if this submission is the first incomplete
                                # submission created for this $job.
                                my $job = $sub->job;
                                if ($job->block_and_skip_if_ok) {
                                    my ($first_sub) = VRPipe::Submission->search({ 'job' => $job->id, '_done' => 0 }, { rows => 1, order_by => { -asc => 'id' } });
                                    next unless ($first_sub && $first_sub->id == $sub_id);
                                }
                                
                                # global step limit handling
                                my $step       = $sub->stepstate->stepmember->step;
                                my $step_id    = $step->id;
                                my $step_limit = _get_steplimit($step, \%step_limits, \%completed_setups, \%step_counts);
                                if ($step_limit) {
                                    next if $step_counts{$step_id} >= $step_limits{$step_id};
                                }
                                
                                # we'll want to make sure there'll be a
                                # handler for this one
                                $req_counts{$req_id}++;
                                $step_counts{$step_id}++;
                                
                                next if exists $already_taken{$req_id}->{$sub_id};
                                next if $sub->noted('grabbed');
                                next if $sub->locked;
                                next if $sub->job->locked;
                                
                                #*** note the race condition between testing
                                # if a handler grabbed it above, and adding it
                                # to the queue below: the handler could grab it
                                # right now and we won't know. multi doesn't
                                # seem to help, because we can't see any values
                                # during a multi, so can't stop the sadd from
                                # happening if grabbed exists
                                
                                # queue this one in redis
                                $im->enqueue($req_id, $sub_id);
                                $redis_queue{$req_id}->{$sub_id} = 1;
                            }
                        }
                        
                        # scale the counts according to $max_subs
                        #*** and eventually, we should have a priority system
                        #    where a particular setup can have higher priority
                        #    than others...
                        if ($max_subs) {
                            my $total_count = 0;
                            foreach my $count (values %req_counts) {
                                $total_count += $count;
                            }
                            
                            if ($total_count > $max_subs) {
                                my $reducer = $max_subs / $total_count;
                                while (my ($req_id, $count) = each %req_counts) {
                                    $req_counts{$req_id} = floor($count * $reducer);
                                    $req_counts{$req_id} ||= 1;
                                }
                            }
                        }
                        
                        # remove from the redis queue what we no longer need
                        my @req_ids = VRPipe::Requirements->get_column_values('me.id', {});
                        foreach my $req_id (@req_ids) {
                            unless (exists $redis_queue{$req_id}) {
                                $im->drop_queue($req_id);
                                next;
                            }
                            
                            my $sub_ids = $im->queue($req_id);
                            my @to_rem;
                            foreach my $sub_id (@$sub_ids) {
                                next if exists $redis_queue{$req_id}->{$sub_id};
                                push(@to_rem, $sub_id);
                            }
                            $im->dequeue($req_id, \@to_rem) if @to_rem;
                        }
                        
                        # submit the submission handlers to the scheduler
                        my %running_in_scheduler;
                        while (my ($req_id, $count) = each %req_counts) {
                            my $cmd = "$handler_path --mode submissions --farm $farm -r $req_id -s $sched_id";
                            
                            #$im->log("will ensure that $count sub handlers are running for [$cmd]");
                            my @running_sids = $scheduler->ensure_running(
                                cmd   => $cmd,
                                count => $count,
                                $deployment eq 'testing' ? (cwd => $cwd) : (),
                                requirements => VRPipe::Requirements->get(id => $req_id),
                            );
                            
                            foreach my $sid_aid (@running_sids) {
                                $running_in_scheduler{$sid_aid} = 1;
                            }
                        }
                        
                        # delete any old defunct or stuck SidToSubs, and kill
                        # them from the scheduler as well
                        my $leeway = $deployment eq 'production' ? 300 : 60;
                        my @sids_to_kill;
                        foreach my $sidtosub (VRPipe::SidToSub->search({ farm => $farm })) {
                            my $sid     = $sidtosub->sid;
                            my $aid     = $sidtosub->aid;
                            my $sid_aid = "$sid\[$aid]";
                            my $dstr    = "[sidtosub " . $sidtosub->id . " sid $sid_aid]";
                            #$im->debug("$dstr checking if defunct");
                            
                            unless (exists $running_in_scheduler{$sid_aid}) {
                                #$im->debug("$dstr don't know that the scheduler is running this sid");
                                # we might not know it's running because
                                # %running_in_scheduler is only populated for
                                # req_ids we still needed to run, so check with
                                # the scheduler
                                my $status = $scheduler->sid_status($sid, $aid);
                                #$im->debug("$dstr sid_status said $status");
                                if ($status eq 'RUN') {
                                    $running_in_scheduler{$sid_aid} = 1;
                                }
                            }
                            
                            if (exists $running_in_scheduler{$sid_aid}) {
                                # check that it has not been longer than 5mins
                                # between sid_id being assigned and the sub's
                                # job starting
                                #$im->debug("$dstr it is currently running");
                                my $sub_id = $sidtosub->sub_id;
                                
                                if ($sub_id) {
                                    #$im->debug("$dstr it has been assigned a sub_id sub $sub_id");
                                    my ($sub) = VRPipe::Submission->search({ 'me.id' => $sub_id }, { prefetch => 'job' });
                                    if ($sub) {
                                        # if sub done/failed, the handler will soon
                                        # unset sub_id and we want it to hang around
                                        # until we assign it a new one
                                        my $kill = 0;
                                        if ($sub->done || $sub->failed) {
                                            # however, the handler could get
                                            # stuck in between the submission
                                            # getting set done and the sub_id
                                            # getting unset, so check for that
                                            # now. Yet we also want to avoid
                                            # killing it while its in the middle
                                            # of triggering, and that can take
                                            # over 5mins when the db is heavily
                                            # loaded, so we rely on the redis
                                            # lock version of the job's heart
                                            # beat, which runs until the trigger
                                            # is over
                                            my $job = $sub->job;
                                            next if $job->locked;
                                            my $job_end = $job->end_time;
                                            if (!$job_end || time() > ($job_end->epoch + ($leeway * 3))) {
                                                $im->log("$dstr is currently running, but its claimed submission finished ages ago");
                                                $kill = 1;
                                            }
                                            else {
                                                next;
                                            }
                                        }
                                        #$im->debug("$dstr that sub isn't done yet");
                                        
                                        unless ($kill) {
                                            # if the job has started and is running, all
                                            # is well
                                            next if $sub->job->locked;
                                            #$im->debug("$dstr the job is dead or hasn't started yet");
                                            
                                            next if $sidtosub->time_since_assignment <= $leeway;
                                            $im->log("$dstr it's been over 5mins since assignment and the job (" . $sub->job->id . ") is dead or hasn't started yet");
                                        }
                                    }
                                }
                                else {
                                    # it hasn't grabbed a sub_id yet, but is
                                    # that because we don't need a handler for
                                    # this req_id anymore?
                                    my $req_id = $sidtosub->req_id;
                                    unless ($req_counts{$req_id}) {
                                        #$im->debug("$dstr it has not grabbed a sub_id because we no longer need a handler for req $req_id");
                                    }
                                    else {
                                        # ok, we still need it, perhaps it got
                                        # stuck? When the submission handler
                                        # undefs a submission it also updates
                                        # assignment time, so we can see how
                                        # long it has been sitting undefined
                                        next if $sidtosub->time_since_assignment <= $leeway;
                                        #$im->debug("$dstr it's been over 5mins since the handler tried to get a new submission");
                                    }
                                }
                                
                                #$im->debug("$dstr we'll ask the scheduler to kill this");
                                push(@sids_to_kill, [$sid, $aid]);
                            }
                            
                            # if we got this far it means either we're running
                            # with an assigned sub but aren't doing anything
                            # with it (we are stuck), or we're not running so
                            # must have exited
                            #$im->debug("$dstr we'll delete the sidtosub");
                            $sidtosub->delete;
                        }
                        
                        # kill anything running in the scheduler for which there
                        # has not been a sidtosub created for over 5 mins
                        foreach my $sid_aid (keys %running_in_scheduler) {
                            my ($sid, $aid) = $sid_aid =~ /(\d+)\[(\d+)/;
                            my $created = VRPipe::SidToSub->search({ farm => $farm, sid => $sid, aid => $aid });
                            unless ($created) {
                                my $run_time = $scheduler->run_time($sid, $aid);
                                if ($run_time > $leeway) {
                                    $im->log("we'll kill sid $sid\[$aid] because it never created a sidtosub");
                                    push(@sids_to_kill, [$sid, $aid]);
                                }
                            }
                        }
                        
                        # batch kill sids now
                        $scheduler->kill_sids(\@sids_to_kill);
                    }
                    
                    alarm 0;
                    return;
                }
                sub {
                    $still_working = 0;
                    my $err = $@;
                    if ($err) {
                        # perhaps another process decided our $farm_server was
                        # no longer alive and it has been deleted from the db?
                        # let's still keep the farmserver watcher alive so we
                        # will try and re-register as a farmserver - necessary
                        # when running a bunch of tests where the database keeps
                        # getting dropped and recreated while the server is
                        # running
                        if ($err =~ /^farmserver/) {
                            chomp($err);
                            $im->log("Could not continue submission management for farm $farm because $err.", email_admin => 1);
                            $farm_server->unlock;
                            undef $farm_server;
                        }
                        &{$watcher_error_sub};
                    }
                };
            }
        };
    }
    
    # set up the http page requests we'll respond to
    $backend->register_psgi_pages(
        '/' => sub {
            $backend->psgi_file_response(file($dist_dir, 'web_interface.html')->stringify, shift);
        },
        '/login_template.html' => sub {
            $backend->psgi_file_response(file($dist_dir, 'login_template.html')->stringify, shift);
        },
        '/js/(.+\.js)$' => sub {
            my ($env, $basename) = @_;
            $backend->psgi_file_response(file($dist_dir, 'js', $basename)->stringify, $env, max_age => 525200);
        },
        '/css/(.+\.(?:css|png|gif))$' => sub {
            my ($env, $basename) = @_;
            $backend->psgi_file_response(file($dist_dir, 'css', $basename)->stringify, $env, max_age => 525200);
        },
        '/fonts/(.+)$' => sub {
            my ($env, $basename) = @_;
            $backend->psgi_file_response(file($dist_dir, 'fonts', $basename)->stringify, $env, max_age => 525200);
        },
        '/pages/(.+)$' => sub {
            my ($env, $path) = @_;
            $path =~ s/[\?#].+$//;
            $path =~ s/\/$//;
            my $abs = file($dist_dir, 'pages', $path);
            if (exists $pages{ $abs->basename }) {
                $abs = file($abs, 'index.html');
            }
            $backend->psgi_file_response($abs->stringify, $env, max_age => 525200);
        },
        '/file/(.+)$' => sub {
            my ($env, $path) = @_;
            $backend->psgi_file_response('/' . $path, $env, check_permissions => 1);
        },
        '/rest/status/(.+)$' => sub {
            my ($env, $method) = @_;
            $backend->psgi_nonblocking_json_response($graph, \&status, $env, $method);
        },
        '/rest/graph/(.+)$' => sub {
            my ($env, $method) = @_;
            $backend->psgi_nonblocking_json_response($graph, \&graph, $env, $method);
        },
        '/rest/qc/(.+)$' => sub {
            my ($env, $method) = @_;
            $backend->psgi_nonblocking_json_response($graph, \&qc, $env, $method);
        },
        '/rest/authenticate' => sub {
            $backend->psgi_nonblocking_json_response($graph, \&authenticate_via_pam, shift);
        },
        '/rest/authenticated_user' => sub {
            $backend->psgi_nonblocking_json_response($graph, \&authenticated_user, shift);
        },
        '/rest/deauthenticate_user' => sub {
            $backend->psgi_nonblocking_json_response($graph, \&deauthenticate_user, shift);
        },
        '/dsn' => sub {
            $backend->psgi_text_response(200, 'plain', $backend->dsn, shift);
        },
        '/stop' => sub {
            shutdown_server("Received the stop command");
            $backend->psgi_text_response(200, 'plain', 'Stopping server', shift);
        }
    );
    
    # set up the signals we'll react to
    $SIG{HUP}  = 'IGNORE';
    $SIG{PIPE} = 'IGNORE';
    my $sigterm_watcher = EV::signal 'TERM', sub { shutdown_server("SIGTERM received"); };
    my $sigint_watcher  = EV::signal 'INT',  sub { shutdown_server("SIGINT received"); };
    my $sigquit_watcher = EV::signal 'QUIT', sub { shutdown_server("SIGQUIT received"); };
    
    # run the event loop
    $im->log("The $deployment server at $url for VRPipe database " . $backend->dsn . " has started for farm $farm (pid $$).", email_admin => 1, subject => 'The VRPipe Server is alive!') if $farm;
    EV::run;
    
    # cleanup handlers when testing (but not in production, since handlers
    # should keep running if the server goes down)
    eval {
        if ($farm_server) {
            $farm_server->unlock;
            $farm_server->delete;
        }
    };
    if ($deployment eq 'testing') {
        # make sure all our handlers have exited ***... I don't know of a good
        # way to ensure this; let's just wait 6 seconds and hope they commit
        # suicide now that the farmserver is gone
        sleep(6);
        
        # some schedulers may need to do something when the test server exits
        my $sch_on_exit_method = $scheduler ? $scheduler->on_exit_method : undef;
        if ($sch_on_exit_method) {
            $scheduler->scheduler_instance->$sch_on_exit_method;
        }
        
        # flush any remaining redis stderr to file
        &$im_stderr_output_sub() if $im_stderr_output_sub;
        
        # now we can get rid of the redis server
        $im->terminate_datastore;
    }
    
    $im->log("The $deployment server at $url for VRPipe database " . $backend->dsn . " ($farm farm) is exiting!", email_admin => 1, subject => 'The VRPipe Server is dead!') if $farm;
    exit 0;
}

sub shutdown_server {
    my $msg = shift;
    $im->log($msg . ", will gracefully shut down server.");
    EV::unloop;
}

sub _get_steplimit {
    my ($step, $step_limits, $completed_setups, $step_counts) = @_;
    my $step_id = $step->id;
    
    my $step_limit;
    if (exists $step_limits->{$step_id}) {
        $step_limit = $step_limits->{$step_id};
    }
    else {
        # figure out what the step limit is, if any,
        # by checking the config of every incomplete
        # & active setup that uses the step
        my @setups = VRPipe::PipelineSetup->search({ active => 1, 'step.id' => $step_id }, { join => { 'pipeline' => { 'stepmembers' => 'step' } } });
        if (@setups) {
            my $step_name = $step->name;
            foreach my $setup (@setups) {
                unless (exists $completed_setups->{ $setup->id }) {
                    $completed_setups->{ $setup->id } = $setup->currently_complete;
                }
                next if $completed_setups->{ $setup->id };
                my $setup_limit = $setup->options->{ $step_name . '_max_simultaneous' } || next;
                if (!defined $step_limit || $setup_limit < $step_limit) {
                    $step_limit = $setup_limit;
                }
            }
        }
        if (!defined $step_limit) {
            # also check the step itself for a limit
            $step_limit = $step->max_simultaneous;
        }
        $step_limits->{$step_id} = $step_limit || 0;
        
        if ($step_limit) {
            # see how many of this step are currently
            # running, globally
            my $pager = VRPipe::Submission->search_paged({ 'stepmember.step' => $step_id, '_done' => 0, '_failed' => 0 }, { join => { stepstate => 'stepmember' }, prefetch => 'job' });
            my $count = 0;
            while (my $subs = $pager->next) {
                foreach my $sub (@$subs) {
                    $count++ if $sub->job->locked;
                }
            }
            $step_counts->{$step_id} = $count;
        }
    }
    
    return $step_limit;
}

# "page" subs
sub authenticate_via_pam {
    my $args = shift;
    
    my $auth_hash = authenticated_user($args);
    
    if (!$auth_hash->{user} && $args->{user} && $args->{password}) {
        # user has supplied their username and password and wants to
        # authenticate for the first time since we started up
        my $user = $args->{user};
        
        # prevent rapid-fire brute-force login attempts; PAM itself
        # probably prevents brute-force, but I don't know how it's
        # configured, so I implement this myself
        return $auth_hash unless $im->rate_limit('authenticate_via_pam.' . $user, punish_excess => 1);
        
        my $pam = Authen::Simple::PAM->new(service => "login");
        if ($pam->authenticate($user, $args->{password})) {
            # delete any existing session
            my $session = $args->{vrpipe_session};
            if ($session) {
                $im->drop_session($session);
            }
            
            # store the user (implying authentication success) in redis under
            # a new session (using default lax expiry that allows a session to
            # last for a working week if user loads a new page once per day and
            # does not close their browser window)
            $session = $im->create_session({ user => $user });
            
            # return json that says we're successful by presenting the validated
            # username (just for client presentational purposes), and the
            # vrpipe_session string which will be placed in the client's cookie
            $auth_hash->{user}           = $user;
            $auth_hash->{vrpipe_session} = $session;
        }
    }
    
    return $auth_hash;
}

sub authenticated_user {
    my $args = shift;
    
    my $user;
    
    my $session = $args->{vrpipe_session};
    if ($session) {
        # check redis to see what session data we have for this user
        my $session_hash = $im->get_session($session);
        
        # if we have data for the supplied session, and if there's a user,
        # they've previously authenticated successfully
        if ($session_hash && defined $session_hash->{user}) {
            $user = $session_hash->{user};
        }
        else {
            # their session expired in some way
            delete $args->{vrpipe_session};
        }
    }
    
    return { user => $user };
}

sub deauthenticate_user {
    my $args    = shift;
    my $session = $args->{vrpipe_session};
    if ($session) {
        $im->drop_session($session);
    }
    return { user => undef, vrpipe_session => '' };
}

sub graph {
    my ($args, $method) = @_;
    
    my $data;
    if ($method eq 'get_schema') {
        my ($uniques, $indexed, $required) = $graph->get_schema(namespace => $args->{namespace}, label => $args->{label});
        $data = { uniques => $uniques, indexed => $indexed, required => $required };
    }
    elsif ($method eq 'root_nodes') {
        $data = { nodes => [$graph->root_nodes()] };
    }
    elsif ($method eq 'relations_of') {
        $data = $graph->related({ id => $args->{start_node} }, undef, { min_depth => 0, max_depth => 1 }, { min_depth => 0, max_depth => $args->{depth} });
    }
    elsif ($method eq 'cypher_match') {
        my $cypher = $args->{cypher};
        if ($cypher =~ /\b(?:create|merge|set|delete|remove)\b/i) {
            $data = { errors => ["Writing clauses are not allowed"] };
        }
        else {
            $data = $graph->_run_cypher([[$cypher]]);
        }
    }
    elsif ($method eq 'get_pages') {
        $data = $pages;
    }
    else {
        $data = { errors => ["Invalid graph method '$method'"] };
    }
    
    return $data;
}

sub status {
    my ($args, $method) = @_;
    
    my $data = {};
    if ($method eq 'get_setup_ids_by_id_or_name') {
        my $ids_or_name = $args->{ids_or_name};
        if ($ids_or_name =~ /^[\d\s,]+$/) {
            # it's one or more setup ids, check they're all valid
            while ($ids_or_name =~ /(\d+)/g) {
                my $id = $1;
                my ($setup) = VRPipe::PipelineSetup->search({ id => $id });
                if ($setup) {
                    push(@{ $data->{ids} }, $id);
                }
                else {
                    push(@{ $data->{errors} }, "No setup with id $id was found.");
                }
            }
        }
        else {
            # it's a setup name, search for matching setups
            my @setups = VRPipe::PipelineSetup->search({ name => { like => '%' . $ids_or_name . '%' } });
            if (@setups) {
                $data->{ids} = [map { $_->id } @setups];
            }
            else {
                $data->{errors} = ["No setups match the name '$ids_or_name'"];
            }
        }
    }
    elsif ($method eq 'get_setup_ids_by_user') {
        my $user        = $args->{user};
        my $incomplete  = $args->{incomplete};
        my $deactivated = $args->{deactivated};
        my @setups      = VRPipe::PipelineSetup->search({ $user eq 'all' ? () : (user => $user), $deactivated ? () : (active => 1) });
        if ($incomplete) {
            foreach my $setup (@setups) {
                next if $setup->currently_complete;
                push(@{ $data->{ids} }, $setup->id);
            }
        }
        else {
            $data->{ids} = [map { $_->id } @setups];
        }
        unless (defined $data->{ids} && @{ $data->{ids} }) {
            my $complete_string = $incomplete ? ' incomplete' : '';
            my $active_string = $deactivated ? '' : ($complete_string ? ', active' : ' active');
            $data->{errors} = ["There are no$complete_string$active_string setups for user '$user'"];
        }
    }
    elsif ($method eq 'get_setups') {
        my $setups = $args->{setups};
        if ($setups) {
            my (@setups, %pipeline_details, %step_details, %datasource_details);
            foreach my $id (sort { $a <=> $b } @$setups) {
                my ($setup) = VRPipe::PipelineSetup->search({ id => $id });
                if ($setup) {
                    my $setup_data = { id => $id };
                    
                    # store simple things as parameters
                    foreach my $col (qw(desired_farm user name active description output_root unix_group controlling_farm)) {
                        my $val = $setup->$col();
                        if ($col eq 'output_root') {
                            $val = $val->stringify;
                        }
                        $setup_data->{parameters}->{$col} = $val;
                    }
                    
                    # store options in their own hashref
                    $setup_data->{options} = $setup->options();
                    
                    # store details of the datasource in its own hashref
                    my $ds    = $setup->datasource();
                    my $ds_id = $ds->id;
                    unless (exists $datasource_details{$ds_id}) {
                        my $ds_data = { id => $ds_id };
                        
                        foreach my $col (qw(id type method source)) {
                            my $val = $ds->$col();
                            $ds_data->{parameters}->{$col} = $val;
                        }
                        
                        $ds_data->{options} = $ds->options();
                        $datasource_details{$ds_id} = $ds_data;
                    }
                    $setup_data->{datasource} = $datasource_details{$ds_id};
                    
                    # store details of the pipeline in its own hashref
                    my $p    = $setup->pipeline();
                    my $p_id = $p->id;
                    unless (exists $pipeline_details{$p_id}) {
                        my $p_data = { id => $ds_id };
                        
                        foreach my $col (qw(id name description)) {
                            my $val = $p->$col();
                            $p_data->{properties}->{$col} = $val;
                        }
                        
                        my $step_details = [{ id => 0, properties => { id => 0, name => 'DataSource', description => 'Input from the DataSource', max_simultaneous => 0 } }];
                        foreach my $sm ($p->step_members) {
                            my $s    = $sm->step();
                            my $s_id = $s->id;
                            unless (exists $step_details{$s_id}) {
                                my $step_data = { id => $s_id };
                                
                                foreach my $col (qw(id name description max_simultaneous)) {
                                    my $val = $s->$col();
                                    $step_data->{properties}->{$col} = $val;
                                }
                                
                                $step_data->{properties}->{inputs}  = [keys %{ $s->inputs_definition() }];
                                $step_data->{properties}->{outputs} = [keys %{ $s->outputs_definition() }];
                                
                                $step_details{$s_id} = $step_data;
                            }
                            push(@$step_details, $step_details{$s_id});
                        }
                        
                        $p_data->{steps} = $step_details;
                        $pipeline_details{$p_id} = $p_data;
                    }
                    $setup_data->{pipeline} = $pipeline_details{$p_id};
                    my $num_steps = scalar(@{ $setup_data->{pipeline}->{steps} }) - 1;
                    
                    # store details of current progress through the pipeline in
                    # a final hashref
                    my ($progressions, $errors, $warnings);
                    my $num_elements;
                    my $incomplete_pager;
                    
                    eval {
                        $num_elements = VRPipe::DataElementState->search({ pipelinesetup => $id, 'dataelement.datasource' => $ds_id, 'dataelement.withdrawn' => 0 }, { join => 'dataelement' });
                        $incomplete_pager = $ds->incomplete_element_states($setup, prepare => 0);
                    };
                    if ($@ || !$incomplete_pager) {
                        push(@$errors, "There is a problem with the DataSource for this setup, so no more information can be retrieved about it: $@\n");
                        $setup_data->{status} = 'stalled';
                    }
                    else {
                        my $num_incomplete = $incomplete_pager->total_entries;
                        if ($num_incomplete) {
                            my %status_hash;
                            my $fully_complete = $num_elements - $num_incomplete;
                            $status_hash{$num_steps} = $fully_complete if $fully_complete;
                            my $num_steps_complete = $fully_complete * $num_steps;
                            while (my $incompletes = $incomplete_pager->next) {
                                foreach my $es (@$incompletes) {
                                    my $completed_steps = $es->completed_steps;
                                    $num_steps_complete += $completed_steps;
                                    $status_hash{$completed_steps}++;
                                }
                            }
                            
                            my $had_subs = 0;
                            my $failed   = 0;
                            my $unknown  = 0;
                            foreach my $step_num (sort { $a <=> $b } keys %status_hash) {
                                my $completed_els = $status_hash{$step_num};
                                if ($step_num < $num_steps) {
                                    my $pager = VRPipe::Submission->search_paged({ '_done' => 0, 'stepstate.pipelinesetup' => $setup->id, 'stepmember.step_number' => $step_num + 1, 'dataelement.withdrawn' => 0 }, { join => { 'stepstate' => ['dataelement', 'stepmember'] }, prefetch => ['job', 'stepstate'] });
                                    my %sss;
                                    my %ss;
                                    while (my $subs = $pager->next(no_resetting => 1)) {
                                        foreach my $sub (@$subs) {
                                            $had_subs = 1;
                                            my $sub_state;
                                            if ($sub->done) {
                                                $sub_state = 'complete';
                                            }
                                            else {
                                                $sub_state = $sub->failed ? 'failed' : 'scheduled';
                                                if ($sub_state eq 'scheduled') {
                                                    my $job = $sub->job;
                                                    $sub_state = $job->end_time ? 'processing' : ($job->locked ? 'running' : 'pending');
                                                }
                                            }
                                            my $ss_id = $sub->stepstate->id;
                                            $sss{$sub_state}->{$ss_id}++;
                                            $ss{$ss_id} = 1;
                                        }
                                    }
                                    
                                    my $unaccounted_for = $completed_els - scalar(keys %ss);
                                    if ($unaccounted_for) {
                                        push(@$progressions, { step => $step_num, num_elements => $unaccounted_for, percent => _percent_rounder((100 / $num_elements) * $unaccounted_for), status => 'unknown', setup => $id });
                                        $unknown += $unaccounted_for;
                                    }
                                    
                                    foreach my $state (qw(running processing pending failed)) {
                                        my $ss_hash = $sss{$state} || next;
                                        my $num_ss = scalar(keys %$ss_hash);
                                        push(@$progressions, { step => $step_num + 1, num_elements => $num_ss, percent => _percent_rounder((100 / $num_elements) * $num_ss), status => $state, setup => $id });
                                        $failed += $num_ss if $state eq 'failed';
                                    }
                                }
                                else {
                                    push(@$progressions, { step => $step_num, num_elements => $completed_els, percent => _percent_rounder((100 / $num_elements) * $completed_els), status => 'complete', setup => $id });
                                }
                            }
                            
                            my $steps_to_complete = $num_elements * $num_steps;
                            $setup_data->{progress_percent} = _percent_rounder((100 / $steps_to_complete) * $num_steps_complete);
                            
                            my $farm = $setup->controlling_farm;
                            if ($farm) {
                                my ($farm_server) = VRPipe::FarmServer->search({ farm => $farm });
                                if (!$farm_server) {
                                    push(@$errors, "The setup may be stalled because it is being controlled by the VRPipe server for farm $farm, but no server for that farm exists.");
                                }
                                elsif (!$farm_server->locked) {
                                    #*** this is broken, because dead detection
                                    # is based on checking ->locked(), which is
                                    # only asking the local redis server, while
                                    # the server may be running somewhere
                                    # physically else and have its own redis
                                    # server. Detection must be based on a
                                    # last_lock_time column in db...
                                    #push(@$errors, "The setup may be stalled because it is being controlled by the VRPipe server for farm $farm, but the server for that farm seems dead.");
                                }
                            }
                            
                            if ($failed) { #  >= $num_incomplete
                                #push(@$errors, "It looks like this setup may be STALLED due to repeated failures. Investigate using: vrpipe-submissions --setup " . $setup->id . " --failed");
                                $setup_data->{status} = 'stalled';
                            }
                            elsif ($unknown) {
                                $setup_data->{status} = 'unknown';
                            }
                            
                            unless ($had_subs) {
                                # well, what is happening to this setup then? probably we
                                # have the same submissions as some other setup
                                $incomplete_pager = $ds->incomplete_element_states($setup, prepare => 0);
                                my @step_members  = $p->step_members;
                                my $found_problem = 0;
                                ESCHECKER: while (my $incompletes = $incomplete_pager->next) {
                                    foreach my $es (@$incompletes) {
                                        my $element         = $es->dataelement;
                                        my $completed_steps = $es->completed_steps;
                                        next if $completed_steps == $num_steps;
                                        
                                        foreach my $member (@step_members) {
                                            my $step_number = $member->step_number;
                                            my ($state) = VRPipe::StepState->search({
                                                    stepmember    => $member,
                                                    dataelement   => $element,
                                                    pipelinesetup => $setup
                                                }
                                            );
                                            next unless $state;
                                            next if $state->complete;
                                            
                                            my @submissions = $state->submissions;
                                            if (@submissions) {
                                                my $other_state = $state->same_submissions_as;
                                                if ($other_state) {
                                                    my $other_setup = $other_state->pipelinesetup->id;
                                                    if ($other_setup != $setup->id && $other_state->complete != 1) {
                                                        push(@$warnings, "This setup is dependent on work being done by setup $other_setup, so check the status of that to see what's happening.");
                                                        $found_problem = 1;
                                                        last ESCHECKER;
                                                    }
                                                }
                                            }
                                            else {
                                                # push(@$warnings, "Currently processing step $step_number (" . $member->step->name . "). It's possible something has gone wrong with this step and the setup is stalled; you should have received an email with further details in that case.");
                                                # instead of giving a warning on the setup, user can get the actual error by clicking a progression
                                                $found_problem = 1;
                                                last ESCHECKER;
                                            }
                                        }
                                    }
                                }
                                
                                $setup_data->{status} = 'unknown';
                                unless ($found_problem) {
                                    push(@$warnings, "The setup hasn't completed but there are no submissions for it and I can't detect obvious problems; maybe it's in the middle of processing and something will happen soon.");
                                }
                            }
                        }
                        else {
                            if ($num_elements == 0) {
                                push(@$warnings, "Pipeline has no inputs to work on (yet?), so has done nothing.");
                                $setup_data->{status} = 'unknown';
                            }
                            else {
                                $setup_data->{progress_percent} = 100;
                                $setup_data->{status}           = 'complete';
                                $progressions = [{ step => $num_steps, num_elements => $num_elements, percent => 100, status => 'complete', setup => $id }];
                            }
                        }
                    }
                    $setup_data->{errors}   = $errors;
                    $setup_data->{warnings} = $warnings;
                    $setup_data->{status} ||= 'ok';
                    
                    unless ($progressions && @$progressions) {
                        $setup_data->{progress_percent} ||= 0;
                        if ($num_elements) {
                            $progressions = [{ step => 0, num_elements => $num_elements, percent => 100, status => 'unknown', setup => $id }];
                        }
                        else {
                            $progressions = [{ step => 0, num_elements => 0, percent => 0, status => 'unknown', setup => $id }];
                        }
                    }
                    $setup_data->{progressions} = $progressions;
                    
                    push(@setups, $setup_data);
                }
                else {
                    push(@{ $data->{errors} }, "No setup with id $id was found.");
                }
            }
            
            $data = \@setups;
        }
        else {
            $data->{errors} = ["setups must be supplied to get_setups()"];
        }
    }
    elsif ($method eq 'step_progression_details') {
        my $setup = $args->{setup};
        my $step  = $args->{step};
        my $type  = $args->{type};
        if ($setup && defined $step) {
            my $search_args = {
                $type eq 'failed' ? ('_failed' => 1, '_done' => 0) : ('_done' => $type eq 'complete' ? 1 : 0),
                'stepstate.pipelinesetup' => $setup,
                'stepmember.step_number'  => $step
            };
            my $search_join_args = ['stepstate', { stepstate => { stepmember => 'step' } }];
            my $max_subs = 1000;
            
            my @subs =
              $step
              ? VRPipe::Submission->search(
                $search_args,
                {
                    order_by => { -desc => 'me.id' },
                    rows     => $max_subs,
                    join     => $search_join_args,
                    prefetch => [qw(stepstate job requirements scheduler)]
                }
              )
              : ();
            
            $data->{setup}    = $setup;
            $data->{step_num} = $step;
            
            if (@subs) {
                # get details for an example sub
                my $sub       = $subs[0];
                my $state     = $sub->stepstate;
                my $stepm     = $state->stepmember;
                my $step_num  = $stepm->step_number;
                my $job       = $sub->job;
                my $req       = $sub->requirements;
                my $sub_state = $sub->done ? 'done' : ($sub->failed ? 'failed' : 'scheduled');
                
                $data->{setup_name} = $state->pipelinesetup->name;
                $data->{step_name}  = $stepm->step->name;
                
                my $example_sub_data = {};
                $example_sub_data->{submission_state}       = $sub_state;
                $example_sub_data->{submission_id}          = $sub->id;
                $example_sub_data->{job_id}                 = $job->id;
                $example_sub_data->{dataelement_id}         = $state->dataelement->id;
                $example_sub_data->{submission_retries}     = $sub->retries;
                $example_sub_data->{job_state}              = $job->end_time ? 'finished' : ($job->start_time ? 'running' : 'pending');
                $example_sub_data->{job_host}               = $job->host if defined $job->host;
                $example_sub_data->{job_exit_code}          = $job->exit_code if defined $job->exit_code;
                $example_sub_data->{job_cmd}                = $job->cmd;
                $example_sub_data->{job_dir}                = $job->dir->stringify;
                $example_sub_data->{submission_reserved_mb} = $req->memory;
                my $rsecs = $req->time();
                $example_sub_data->{submission_reserved_seconds} = $rsecs;
                $example_sub_data->{submission_reserved_time}    = _seconds_to_friendly($rsecs);
                
                if ($job->wall_time) {
                    my $mem = $job->peak_memory || '??';
                    my $sec = $job->wall_time;
                    $example_sub_data->{job_actual_mb}      = $mem;
                    $example_sub_data->{job_actual_seconds} = $sec;
                    $example_sub_data->{job_actual_time}    = _seconds_to_friendly($sec);
                }
                
                my $stdout = _submission_std($sub->job_stdout);
                if ($stdout && @$stdout) {
                    $example_sub_data->{job_stdout} = $stdout;
                }
                
                my $stderr = _submission_std($sub->job_stderr);
                if ($stderr && @$stderr) {
                    $example_sub_data->{job_stderr} = $stderr;
                }
                
                $data->{example_submission} = $example_sub_data;
                
                # get a summary of all the subs (we don't use StepStats since
                # we want stats particular to this particular set of @subs)
                my $num_subs = scalar(@subs);
                if ($num_subs == $max_subs) {
                    # get the real count quickly
                    $num_subs = VRPipe::Submission->search($search_args, { join => $search_join_args });
                    if ($num_subs > $max_subs) {
                        $num_subs .= " (stats are for the latest $max_subs subs)";
                    }
                }
                my $submission_summary = { num_submissions => $num_subs };
                
                my (@rmbs, @rsecs, @ambs, @asecs);
                foreach my $sub (@subs) {
                    my $req = $sub->requirements;
                    push(@rmbs,  $req->memory);
                    push(@rsecs, $req->time);
                    
                    my $job = $sub->job;
                    push(@ambs,  $job->peak_memory) if $job->peak_memory;
                    push(@asecs, $job->wall_time)   if $job->wall_time;
                }
                
                $submission_summary->{reserved_mb_percentile}   = _percentile(\@rmbs);
                $submission_summary->{reserved_mb_mean}         = _mean(\@rmbs);
                $submission_summary->{reserved_sec_percentile}  = _percentile(\@rsecs);
                $submission_summary->{reserved_time_percentile} = _seconds_to_friendly($submission_summary->{reserved_sec_percentile});
                $submission_summary->{reserved_sec_mean}        = _mean(\@rsecs);
                $submission_summary->{reserved_time_mean}       = _seconds_to_friendly($submission_summary->{reserved_sec_mean});
                
                if (@ambs) {
                    $submission_summary->{actual_mb_percentile} = _percentile(\@ambs);
                    $submission_summary->{actual_mb_mean}       = _mean(\@ambs);
                }
                if (@asecs) {
                    $submission_summary->{actual_sec_percentile}  = _percentile(\@asecs);
                    $submission_summary->{actual_time_percentile} = _seconds_to_friendly($submission_summary->{actual_sec_percentile});
                    $submission_summary->{actual_sec_mean}        = _mean(\@asecs);
                    $submission_summary->{actual_time_mean}       = _seconds_to_friendly($submission_summary->{actual_sec_mean});
                }
                
                $data->{submission_summary} = $submission_summary;
            }
            else {
                # there are no submissions, try and get at an error
                my $setup_obj = VRPipe::PipelineSetup->get(id => $setup);
                $data->{setup_name} = $setup_obj->name;
                
                # get the step name and step member of the next step
                my $pipeline = $setup_obj->pipeline;
                my @sms      = $pipeline->step_members;
                my $step_member;
                foreach my $sm (@sms) {
                    my $num = $sm->step_number;
                    if ($num == $step) {
                        $data->{step_name} = $sm->step->name;
                    }
                    elsif ($num == $step + 1) {
                        $step_member = $sm;
                        last;
                    }
                }
                $data->{step_name} ||= 'datasource';
                
                # try and trigger an incomplete element through the next
                # step
                my ($des) = VRPipe::DataElementState->search({ pipelinesetup => $setup, completed_steps => $step, 'dataelement.withdrawn' => 0 }, { rows => 1, join => 'dataelement' });
                if ($des) {
                    my $element = $des->dataelement;
                    
                    my $step_state = VRPipe::StepState->create(
                        stepmember    => $step_member,
                        dataelement   => $element,
                        pipelinesetup => $setup_obj
                    );
                    
                    # work out which step inputs each step needs
                    my %step_inputs;
                    foreach my $adaptor (@{ $pipeline->adaptors || [] }) {
                        my $hash = $adaptor->adaptor_hash || next;
                        my %from_steps;
                        while (my ($to_key, $from_keys) = each %{$hash}) {
                            foreach my $from_step (values %{$from_keys}) {
                                next unless $from_step;
                                $from_steps{$from_step} = 1;
                            }
                        }
                        if (keys %from_steps) {
                            $step_inputs{ $adaptor->to_step } = [keys %from_steps];
                        }
                    }
                    
                    # work out the previous step outputs relevant to
                    # the next step
                    my %previous_step_outputs;
                    foreach my $input_step_number (@{ $step_inputs{ $step + 1 } || [] }) {
                        my $input_member = $sms[$input_step_number - 1];
                        my ($input_ss) = VRPipe::StepState->search({ stepmember => $input_member, dataelement => $element, pipelinesetup => $setup_obj });
                        my $input_step = $input_member->step(step_state => $input_ss);
                        while (my ($key, $val) = each %{ $input_step->outputs() }) {
                            $previous_step_outputs{$key}->{$input_step_number} = $val;
                        }
                    }
                    
                    my $parsable_step = $step_member->step(previous_step_outputs => \%previous_step_outputs, step_state => $step_state);
                    my $parse_return;
                    eval { $parse_return = $parsable_step->parse(); };
                    my $error = $@ || $parse_return;
                    if ($error) {
                        $data->{progression_problem} = "Unable to parse the next step (DataElementState " . $des->id . "): $error";
                    }
                    else {
                        $data->{progression_problem} = "Was able to parse the next step without error, so not sure why things are stalled - perhaps something will happen soon? (Or ask the admin to check DataElementState " . $des->id . ', DataElement ' . $element->id . ')';
                    }
                }
                else {
                    $data->{progression_problem} = "Most likely all data elements are withdrawn right now until the setup we depend on has completed.";
                }
            }
        }
        else {
            $data->{errors} = ["setup and step must be supplied to step_progression_details()"];
        }
    }
    else {
        $data->{errors} = ["Invalid status method '$method'"];
    }
    
    return $data;
}

sub _percent_rounder {
    my $percent = shift;
    my $rounded_percent = sprintf("%0.2f", $percent);
    if ($rounded_percent == 100 && $percent < 100) {
        $rounded_percent = 99.99;
    }
    elsif ($rounded_percent == 0 && $percent > 0) {
        $rounded_percent = 0.01;
    }
    return $rounded_percent;
}

sub _percentile {
    my $list    = shift;
    my $percent = shift || 95;
    my @list    = sort { $b <=> $a } @$list;
    @list = sort { $a <=> $b } @$list;
    return $list[sprintf('%.0f', (0.95 * ($#list)))];
}

sub _mean {
    my $list = shift;
    my $sum;
    foreach (@$list) {
        $sum += $_;
    }
    return sprintf('%0.0f', $sum / @$list);
}

sub _seconds_to_friendly {
    my $sec = shift;
    if ($sec <= 60) {
        return "$sec secs";
    }
    
    my $days = int($sec / (24 * 60 * 60));
    my $hrs            = ($sec / (60 * 60)) % 24;
    my $mins           = ($sec / 60) % 60;
    my $remaining_secs = $sec % 60;
    my @friendly;
    foreach ([$days, "$days days"], [$hrs, "$hrs hrs"], [$mins, "$mins mins"], [$remaining_secs, "$remaining_secs secs"]) {
        if ($_->[0]) {
            push(@friendly, $_->[1]);
        }
    }
    return join(', ', @friendly);
}

sub _submission_std {
    my $pars = shift || return;
    my $file = $pars->file;
    
    my @outputs;
    my $lines = $pars->parsed_record;
    my @orig  = ();
    my $got_output;
    while ($pars->next_record) {
        push(@orig, [@{ $pars->parsed_record }]);
        my $num_lines = @$lines;
        my @selected_lines;
        if ($num_lines > 45) {
            for (1 .. 10) {
                push(@selected_lines, $lines->[$_ - 1]);
            }
            my $other_lines = $num_lines - 40;
            push(@selected_lines, "\n[... $other_lines more lines in $file ...]\n\n");
            for (($num_lines - 30) .. $num_lines) {
                push(@selected_lines, $lines->[$_ - 1]);
            }
        }
        else {
            @selected_lines = @$lines;
        }
        
        unless ($got_output) {
            foreach my $line (@selected_lines) {
                if ($line) {
                    $got_output = 1;
                    last;
                }
            }
        }
        
        push(@outputs, \@selected_lines);
    }
    
    return $got_output ? \@outputs : undef;
}

sub qc {
    my ($args, $method) = @_;
    
    unless ($vrtrack) {
        return { errors => ["Could not load up the VRTrack schema in the graph database; is it installed and working?"] };
    }
    
    my $data;
    if ($method eq 'labels') {
        $data = $vrtrack->labels;
    }
    elsif ($method eq 'nodes_of_label') {
        my $label = $args->{label};
        if ($label) {
            my $cypher_labels = $vrtrack->cypher_labels($label);
            
            my $cypher;
            my $groups = $args->{groups};
            if ($groups) {
                my $params       = { group => { ids => $groups } };
                my $group_labels = $vrtrack->cypher_labels('Group');
                my $match        = "MATCH (group:$group_labels) WHERE id(group) IN {group}.ids";
                
                my $studies  = $args->{studies};
                my $previous = 'group';
                my ($donors, $samples);
                if ($studies) {
                    $params->{study}->{ids} = $studies;
                    my $study_labels = $vrtrack->cypher_labels('Study');
                    $match .= " MATCH (group)-->(study:$study_labels) WHERE id(study) IN {study}.ids";
                    $previous = 'study';
                    
                    $donors = $args->{donors};
                    if ($donors) {
                        $params->{donor}->{ids} = $donors;
                        my $donor_labels = $vrtrack->cypher_labels('Donor');
                        $match .= " MATCH ($previous)-->(donor:$donor_labels) WHERE id(donor) IN {donor}.ids";
                        $previous = 'donor';
                    }
                    
                    $samples = $args->{samples};
                    if ($samples) {
                        $params->{sample}->{ids} = $samples;
                        my $sample_labels = $vrtrack->cypher_labels('Sample');
                        $match .= " MATCH ($previous)-->(sample:$sample_labels) WHERE id(sample) IN {sample}.ids";
                        $previous = 'sample';
                    }
                }
                
                my $donor_special;
                if ($label eq 'Donor') {
                    # donor's just have meaningless ids; user will always want
                    # to see the donor's control sample public name and the
                    # most recent created_date of its member samples, so we will
                    # add those as psuedo properties on the donor nodes; first
                    # adjust the cypher to get the donor's samples
                    my $dtsmc = $vrtrack->donor_to_sample_match_cypher('donor');
                    $donor_special = "WITH donor $dtsmc";
                }
                
                my $query;
                if ($label eq 'Donor' && $donors) {
                    $query = $donor_special;
                }
                elsif ($label eq 'Sample' && $samples) {
                    $query = 'RETURN sample';
                }
                else {
                    my $min_d = $args->{min_depth} || 1;
                    my $max_d = $args->{max_depth} || 1;
                    my $depth = "$min_d..$max_d";
                    my $return = 'RETURN n';
                    if ($donor_special) {
                        $donor_special =~ s/donor/n/g;
                        $return = $donor_special;
                    }
                    
                    $query = "MATCH ($previous)-[*$depth]->(n:$cypher_labels) $return";
                }
                
                $cypher = ["$match $query", $params];
            }
            else {
                $cypher = ["MATCH (n:$cypher_labels) RETURN n"];
            }
            
            my $graph_data = $graph->_run_cypher([$cypher]);
            if ($label eq 'Donor') {
                # we have sample nodes related to our donor nodes; figure out
                # which samples belong to which donors, then add the relevant
                # sample properties to the donor node
                $data = $vrtrack->add_sample_info_to_donors($graph_data);
            }
            else {
                if ($label eq 'Sample') {
                    # convert created_date property from epoch to ymd
                    foreach my $sample (@{ $graph_data->{nodes} }) {
                        if (defined $sample->{properties}->{created_date}) {
                            my $dt = DateTime->from_epoch(epoch => $sample->{properties}->{created_date});
                            $sample->{properties}->{created_date} = $dt->ymd;
                        }
                    }
                }
                
                $data = $graph_data->{nodes};
            }
        }
        else {
            $data = { errors => ["label must be supplied to nodes_of_label()"] };
        }
    }
    elsif ($method eq 'node_by_id') {
        my $id = $args->{node_id};
        if ($id) {
            my $label = $args->{label};
            
            if ($label) {
                $data = $vrtrack->get_node_by_id_with_extra_info($label, $id);
            }
            else {
                $data = $graph->get_node_by_id($id);
            }
        }
        else {
            $data = { errors => ["node_id must be supplied to node_by_id()"] };
        }
    }
    elsif ($method eq 'donor_qc') {
        my $donor = $args->{donor};
        if ($donor) {
            # get the discordance results between all samples from this donor
            my $d_results = $vrtrack->donor_discordance_results($donor);
            push(@$data, @$d_results) if $d_results;
            
            # get the gender info for all samples from this donor
            my $g_results = $vrtrack->donor_gender_results($donor);
            push(@$data, @$g_results) if $g_results;
            
            # get the copy number/polysomy/loh results for this donor
            my $c_results = $vrtrack->donor_cnv_results($donor);
            push(@$data, @$c_results) if $c_results;
            
            # get the pluritest results for this donor
            my $p_results = $vrtrack->donor_pluritest_results($donor);
            push(@$data, @$p_results) if $p_results;
        }
        else {
            $data = { errors => ["donor node id must be supplied to donor_qc()"] };
        }
    }
    elsif ($method eq 'sample_discordance') {
        my $sample = $args->{sample};
        if ($sample) {
            # get the discordance results between this sample and all others,
            # along with any donor info to apply to those other samples
            $data = $vrtrack->sample_discordance_results($sample);
        }
        else {
            $data = { errors => ["sample node id must be supplied to sample_discordance()"] };
        }
    }
    else {
        $data = { errors => ["Invalid qc method '$method'"] };
    }
    
    return $data;
}
