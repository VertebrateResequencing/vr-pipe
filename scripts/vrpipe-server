#!/usr/bin/env perl
use strict;
use warnings;

=head1 AUTHOR

Sendu Bala <sb10@sanger.ac.uk>.

=head1 COPYRIGHT AND LICENSE

Copyright (c) 2012-2013 Genome Research Limited.

This file is part of VRPipe.

VRPipe is free software: you can redistribute it and/or modify it under the
terms of the GNU General Public License as published by the Free Software
Foundation, either version 3 of the License, or (at your option) any later
version.

This program is distributed in the hope that it will be useful, but WITHOUT ANY
WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A
PARTICULAR PURPOSE. See the GNU General Public License for more details.

You should have received a copy of the GNU General Public License along with
this program. If not, see L<http://www.gnu.org/licenses/>.

=cut

use EV;
use AnyEvent;
use AnyEvent::Util qw(fork_call);
use VRPipe::Interface::CmdLine;
use VRPipe::Interface::BackEnd;
use Sys::CPU;
use POSIX qw(floor);
use List::Util 'shuffle';
use Path::Class;
use Cwd 'getcwd';
use Digest::MD5;
use VRPipe::Persistent::InMemory;

# handle options
my $cmdline = VRPipe::Interface::CmdLine->new(
    description => "Control the VRPipe server, which provides the web and cmdline interfaces and keeps the pipeline system itself running by submitting things to the scheduler.",
    extra_args  => 'start|stop|restart|status',
    opt_spec    => [
        ['foreground|f',          'Do not daemonize - the server will run in the foreground, logging to STDERR'],
        ['farm=s',                'Discover and dispatch submissions to the job scheduler identified by the supplied name (only 1 server can dispatch to each farm)'],
        ['max_submissions|m=i',   'The maximum number of submissions to dispatch to the farm when in --farm mode (default is unlimited)'],
        ['only_specified_setups', 'In --farm mode, normally any PipelineSetups that have no farm configured will be run on a random farm, so potentially via this server; turning this option on means this server will only handle setups configured for this farm'],
        [],
        ['debug', 'turn lots of debugging output on']
    ]
);

my $backend;
my $deployment            = $cmdline->opts('deployment');
my $foreground            = $cmdline->opts('foreground');
my $farm                  = $cmdline->opts('farm');
my $max_subs              = $cmdline->opts('max_submissions');
my $only_specified_setups = $cmdline->opts('only_specified_setups') || 0;
my $debug                 = $cmdline->opts('debug');
my $scheduler;
my $im = VRPipe::Persistent::InMemory->new();

my $command = shift;
unless ($command) {
    $cmdline->error("a command is required");
    $cmdline->help;
}

# act on the given command
my $status = $cmdline->check_server(1);
my (undef, $port, $url) = @{ $cmdline->_ua_port_baseurl };
my $exit = 0;
if ($command eq 'status') {
    if ($status == 1) {
        $cmdline->output("VRPipe $deployment server is running at $url");
    }
    elsif ($status == 0) {
        $cmdline->output("VRPipe $deployment server is not running");
    }
    elsif ($status == -1) {
        $cmdline->output("A server is listening on port $port, but is not responding like our own VRPipe $deployment server would");
    }
}
elsif ($command eq 'stop') {
    my $stopped = stop();
    $exit = !$stopped;
}
elsif ($command eq 'start') {
    my $started = start();
    $exit = !$started;
}
elsif ($command eq 'restart') {
    $cmdline->output("Restarting VRPipe $deployment server...");
    my $stopped = stop();
    my $started = 0;
    if ($stopped) {
        my $started = start();
    }
    $exit = !$started;
}
else {
    $cmdline->die_with_error("$command is an invalid command");
}

exit $exit;

sub stop {
    if ($status == 1) {
        my $response = $cmdline->server_get('/stop');
        if ($response eq 'Stopping server') {
            # the server responded that it would stop; give it up to 5 seconds
            # to actually do that
            my $seconds = 5;
            while ($seconds--) {
                $status = $cmdline->check_server(1);
                last if $status == 0;
                sleep(1);
            }
            
            if ($status == 0) {
                $cmdline->output("VRPipe $deployment server was stopped");
                return 1;
            }
            else {
                $cmdline->output("VRPipe $deployment server claimed it would stop, but it still seems to be running");
                return 0;
            }
        }
        else {
            $cmdline->output("Failed to stop VRPipe $deployment server (it responded: '$response')");
            return 0;
        }
    }
    elsif ($status == 0) {
        $cmdline->output("VRPipe $deployment server was not running");
        return 1;
    }
    elsif ($status == -1) {
        $cmdline->output("Will not attempt to stop the VRPipe $deployment server listening on port $port, since it does not seem to be ours");
        return 0;
    }
}

sub start {
    if ($status == 1) {
        $cmdline->output("VRPipe $deployment server is already running");
        return 1;
    }
    elsif ($status == 0) {
        $cmdline->output("Will start VRPipe $deployment server at $url");
        start_server();
    }
    elsif ($status == -1) {
        $cmdline->output("Will not attempt to start the VRPipe $deployment server, since another incompatible server is already listening on port $port");
        return 0;
    }
}

sub start_server {
    # initialize the VRPipe backend
    $backend = VRPipe::Interface::BackEnd->new(deployment => $deployment, $farm ? (farm => $farm) : ());
    my $dtf = $backend->schema->storage->datetime_parser;
    if ($debug || $deployment eq 'testing') {
        $backend->set_verbose_global(1);
    }
    
    # daemonize unless we're not supposed to
    my $cwd = getcwd();
    $backend->daemonize unless $foreground;
    
    $AnyEvent::Util::MAX_FORKS = Sys::CPU::cpu_count();
    my $timer_interval = $deployment eq 'production' ? 30 : 5;
    my $inter_message_time = 3600;
    
    my $watcher_error_sub = sub {
        my $err = $@ || return;
        
        # when testing, we likely start the server and call some database-
        # requiring method before the VRPipe database has been created,
        # so we make a nicer error message
        if (ref($err)) {
            $err = "$err"; # try and stringify it
        }
        my $email_admin = 1;
        if ($err =~ /no such table/) {
            $err         = 'VRPipe database not created yet, cannot do all functions';
            $email_admin = 0;
        }
        
        # only log the same error message once per hour
        # try and make the 'same' error message that differs only by
        # references in stack traces literally the same
        my $standardised_error = $err;
        $standardised_error =~ s/(SCALAR|ARRAY|HASH|CODE|REF)\([^\)]+\)/$1()/g;
        
        # get the md5 checksum of the message to use as a key name for
        # a redis lock
        my $dmd5 = Digest::MD5->new();
        $dmd5->add($standardised_error);
        my $checksum = $dmd5->hexdigest;
        
        # do not log if we can't get a lock
        unless ($im->lock($checksum, unlock_after => $inter_message_time)) {
            return;
        }
        
        $im->log($err, email_admin => $email_admin);
    };
    
    # set up a timer that will write out stderr (which includes logs) to the log
    # file. (we do this because writing to a single file from thousands of
    # processes can cripple performance, so instead our single server process
    # does all the writing without slowing down anything else)
    my $err_watcher;
    my $im_stderr_output_sub;
    unless ($foreground) {
        my $working = 0;
        $im_stderr_output_sub = sub {
            return if $working;
            $working = 1;
            fork_call {
                $im->write_stderr;
                return;
            }
            sub { $working = 0; };
        };
        $err_watcher = EV::timer 0, $timer_interval, $im_stderr_output_sub;
    }
    
    # (for timers we use periodic instead of timer because timer seems to have
    # some bug where on the first invocation it happens twice at ~the same time,
    # which can be terrible for us. periodic (usually) does not)
    
    # set up the submission management system if we're supposed to
    my ($farm_server, $farm_watcher, $handler_path, $still_working, $scheduler_watcher);
    my $fork_alarm_time = $deployment eq 'production' ? 3600 : 900;
    if ($farm) {
        # every 30s we'll update which PipelineSetups we'll handle, and also
        # submit handlers to the farm and assign submissions to those handlers
        $farm_watcher = EV::periodic 0, $timer_interval, 0, sub {
            return if $still_working;
            $still_working = 1;
            
            unless ($farm_server) {
                # ideally we only want to be in this if ($farm) section if we
                # have managed to register_farm_server(), but we can only do
                # that once the database is ready, which won't be the case
                # whilst testing. So we use our timer to keep trying to get the
                # farm_server whilst it fails due to database issues, but cancel
                # the timer if we fail because another server is handling this
                # farm
                eval { $farm_server = $backend->register_farm_server($farm, only_ours => $only_specified_setups) };
                if ($@) {
                    &{$watcher_error_sub};
                }
                elsif ($farm_server) {
                    # our database must be ready now, so load all Pipeline and
                    # Step .pm modules into db if we haven't already. we do this
                    # async since if it takes too long the farm_server will
                    # think it died and we'll immediately lose it!
                    unless ($deployment eq 'testing') {
                        fork_call {
                            $backend->install_pipelines_and_steps;
                            return;
                        }
                        $watcher_error_sub;
                    }
                    
                    $im->log("Submission management started for farm $farm");
                    $handler_path = $cmdline->vrpipe_script_command('vrpipe-handler', $deployment);
                    $handler_path =~ s/^\S+perl/perl/; # different nodes may have different perls installed at different locations
                    $scheduler = VRPipe::Scheduler->create();
                    $scheduler->initialize_for_server;
                    
                    # some schedulers may need to do something periodically;
                    # set up a watcher for that now
                    my $sch_periodic_method = $scheduler->periodic_method;
                    if ($sch_periodic_method) {
                        my $working            = 0;
                        my $scheduler_interval = $timer_interval * 10;
                        $scheduler_watcher = EV::timer 0, $scheduler_interval, sub {
                            return if $working;
                            $working = 1;
                            fork_call {
                                return $scheduler->scheduler_instance->$sch_periodic_method(deployment => $deployment);
                            }
                            sub {
                                if (@_ && $scheduler->scheduler_instance->can($_[0])) {
                                    my ($method, @args) = @_;
                                    $scheduler->scheduler_instance->$method(@args);
                                }
                                $working = 0;
                                $@ || return;
                                &{$watcher_error_sub};
                            };
                        };
                    }
                    # make sure the redis server is alive
                    my $ok = $im->datastore_ok;
                    unless ($ok) {
                        $im->log("Can't continue submission management because I can't connect to the in-memory datastore");
                        $farm_server->unlock;
                        $farm_server->delete;
                        undef $farm_server;
                    }
                }
                else {
                    $im->log("Could not start submission management for farm $farm because some other server process is (or was recently) doing that");
                    undef $farm_server;
                }
                $still_working = 0;
            }
            else {
                my $still_locked = $farm_server->locked(by_me => 1);
                
                fork_call {
                    # this fork_call should not take that long, but it is
                    # critical that it not get stuck, or the server will seem to
                    # still be running fine yet won't be submitting any jobs. So
                    # we set up an alarm to kill it after a while
                    local $SIG{ALRM} = sub { die "Taking suspiciously long to ensure that the handlers are running; is the VRPipe database running OK, and is the job scheduler responsive?\n" };
                    alarm $fork_alarm_time;
                    
                    # check we're still valid
                    die "farmserver ", $farm_server->id, " is no longer locked\n" unless $still_locked;
                    my $in_db = $farm_server->search({ id => $farm_server->id });
                    die "farmserver ", $farm_server->id, " is no longer in the database\n" unless $in_db;
                    
                    # claim our setups
                    my @setups = grep { !$_->currently_complete } $farm_server->claim_setups;
                    
                    if (@setups) {
                        # make sure the redis server is alive
                        my $ok = $im->datastore_ok;
                        unless ($ok) {
                            $im->log("Can't continue submission management because I can't connect to the in-memory datastore");
                            undef $farm_server;
                            return;
                        }
                        
                        # make sure we have a setups handler running for our
                        # farm. since our setups handler will run on a node
                        # and needs access to the t directory when testing, we
                        # will cd to the git root first for scheduler that need
                        # to
                        my $shcmd = "$handler_path --mode setups --farm $farm";
                        $scheduler->ensure_running(
                            cmd => $shcmd,
                            $deployment eq 'testing' ? (cwd => $cwd) : (),
                            requirements => VRPipe::Requirements->create(memory => 1500, time => 3600)
                        );
                        # (in production this submits a job to the scheduler
                        #  with a name like *9762b9ae16282af15a8d855bd55c8fa5*)
                        
                        # make sure we have sufficient submission handlers
                        # running...
                        
                        # get the count of requirements. Sadly we can't do a
                        # quick cursor->all because we need to take into account
                        # step limits. Also, to avoid handlers running a slow,
                        # complex query and possibly hitting transaction lock/
                        # database update inconsistency issues, instead of them
                        # selecting a Submission with normal db query they will
                        # get one from the redis queue we will make
                        my %already_taken;
                        my $req_to_subs = VRPipe::SidToSub->get_column_values(['req_id', 'sub_id'], { farm => $farm, sub_id => { '!=' => undef } });
                        foreach my $ref (@$req_to_subs) {
                            my ($req_id, $sub_id) = @$ref;
                            $already_taken{$req_id}->{$sub_id} = 1;
                        }
                        # (we have this in case the redis server goes down and
                        #  we lose that knowledge of what was grabbed)
                        
                        my $sched_id = $scheduler->id;
                        my $sub_pager = VRPipe::Submission->search_paged({ '_done' => 0, -or => [-and => ['_failed' => 1, retries => { '<' => 3 }], '_failed' => 0], scheduler => $sched_id, 'pipelinesetup.controlling_farm' => $farm, 'pipelinesetup.active' => 1, 'dataelement.withdrawn' => 0 }, { join => { stepstate => ['pipelinesetup', 'dataelement'] }, prefetch => ['requirements', 'job', { stepstate => { stepmember => 'step' } }] });
                        
                        my (%req_counts, %step_limits, %step_counts, %completed_setups, %redis_queue);
                        while (my $subs = $sub_pager->next(no_resetting => 1)) {
                            foreach my $sub (@$subs) {
                                my $sub_id = $sub->id;
                                my $req    = $sub->requirements;
                                my $req_id = $req->id;
                                
                                # delay looking at subs with this req_id while
                                # handler's are in the process of generating
                                # new subs with this req_id; this way we're more
                                # likely to get single large arrays for greater
                                # efficiency
                                next if $req->noted('generating_subs');
                                
                                # if the job is a block_and_skip_if_ok job, we
                                # don't actually block because of race condition
                                # issues, and because of fail and restart
                                # issues. Instead we always only actually queue
                                # if this submission is the first incomplete
                                # submission created for this $job.
                                my $job = $sub->job;
                                if ($job->block_and_skip_if_ok) {
                                    my ($first_sub) = VRPipe::Submission->search({ 'job' => $job->id, '_done' => 0 }, { rows => 1, order_by => { -asc => 'id' } });
                                    next unless ($first_sub && $first_sub->id == $sub_id);
                                }
                                
                                # global step limit handling
                                my $step       = $sub->stepstate->stepmember->step;
                                my $step_id    = $step->id;
                                my $step_limit = _get_steplimit($step, \%step_limits, \%completed_setups, \%step_counts);
                                if ($step_limit) {
                                    next if $step_counts{$step_id} >= $step_limits{$step_id};
                                }
                                
                                # we'll want to make sure there'll be a
                                # handler for this one
                                $req_counts{$req_id}++;
                                $step_counts{$step_id}++;
                                
                                next if exists $already_taken{$req_id}->{$sub_id};
                                next if $sub->noted('grabbed');
                                next if $sub->locked;
                                next if $sub->job->locked;
                                
                                #*** note the race condition between testing
                                # if a handler grabbed it above, and adding it
                                # to the queue below: the handler could grab it
                                # right now and we won't know. multi doesn't
                                # seem to help, because we can't see any values
                                # during a multi, so can't stop the sadd from
                                # happening if grabbed exists
                                
                                # queue this one in redis
                                $im->enqueue($req_id, $sub_id);
                                $redis_queue{$req_id}->{$sub_id} = 1;
                            }
                        }
                        
                        # scale the counts according to $max_subs
                        #*** and eventually, we should have a priority system
                        #    where a particular setup can have higher priority
                        #    than others...
                        if ($max_subs) {
                            my $total_count = 0;
                            foreach my $count (values %req_counts) {
                                $total_count += $count;
                            }
                            
                            if ($total_count > $max_subs) {
                                my $reducer = $max_subs / $total_count;
                                while (my ($req_id, $count) = each %req_counts) {
                                    $req_counts{$req_id} = floor($count * $reducer);
                                    $req_counts{$req_id} ||= 1;
                                }
                            }
                        }
                        
                        # remove from the redis queue what we no longer need
                        my @req_ids = VRPipe::Requirements->get_column_values('me.id', {});
                        foreach my $req_id (@req_ids) {
                            unless (exists $redis_queue{$req_id}) {
                                $im->drop_queue($req_id);
                                next;
                            }
                            
                            my $sub_ids = $im->queue($req_id);
                            my @to_rem;
                            foreach my $sub_id (@$sub_ids) {
                                next if exists $redis_queue{$req_id}->{$sub_id};
                                push(@to_rem, $sub_id);
                            }
                            $im->dequeue($req_id, \@to_rem) if @to_rem;
                        }
                        
                        # submit the submission handlers to the scheduler
                        my %running_in_scheduler;
                        while (my ($req_id, $count) = each %req_counts) {
                            my $cmd = "$handler_path --mode submissions --farm $farm -r $req_id -s $sched_id";
                            
                            #$im->log("will ensure that $count sub handlers are running for [$cmd]");
                            my @running_sids = $scheduler->ensure_running(
                                cmd   => $cmd,
                                count => $count,
                                $deployment eq 'testing' ? (cwd => $cwd) : (),
                                requirements => VRPipe::Requirements->get(id => $req_id),
                            );
                            
                            foreach my $sid_aid (@running_sids) {
                                $running_in_scheduler{$sid_aid} = 1;
                            }
                        }
                        
                        # delete any old defunct or stuck SidToSubs, and kill
                        # them from the scheduler as well
                        my $leeway = $deployment eq 'production' ? 300 : 60;
                        my @sids_to_kill;
                        foreach my $sidtosub (VRPipe::SidToSub->search({ farm => $farm })) {
                            my $sid     = $sidtosub->sid;
                            my $aid     = $sidtosub->aid;
                            my $sid_aid = "$sid\[$aid]";
                            my $dstr    = "[sidtosub " . $sidtosub->id . " sid $sid_aid]";
                            #$im->debug("$dstr checking if defunct");
                            
                            unless (exists $running_in_scheduler{$sid_aid}) {
                                #$im->debug("$dstr don't know that the scheduler is running this sid");
                                # we might not know it's running because
                                # %running_in_scheduler is only populated for
                                # req_ids we still needed to run, so check with
                                # the scheduler
                                my $status = $scheduler->sid_status($sid, $aid);
                                #$im->debug("$dstr sid_status said $status");
                                if ($status eq 'RUN') {
                                    $running_in_scheduler{$sid_aid} = 1;
                                }
                            }
                            
                            if (exists $running_in_scheduler{$sid_aid}) {
                                # check that it has not been longer than 5mins
                                # between sid_id being assigned and the sub's
                                # job starting
                                #$im->debug("$dstr it is currently running");
                                my $sub_id = $sidtosub->sub_id;
                                
                                if ($sub_id) {
                                    #$im->debug("$dstr it has been assigned a sub_id sub $sub_id");
                                    my ($sub) = VRPipe::Submission->search({ 'me.id' => $sub_id }, { prefetch => 'job' });
                                    if ($sub) {
                                        # if sub done/failed, the handler will soon
                                        # unset sub_id and we want it to hang around
                                        # until we assign it a new one
                                        my $kill = 0;
                                        if ($sub->done || $sub->failed) {
                                            # however, the handler could get
                                            # stuck in between the submission
                                            # getting set done and the sub_id
                                            # getting unset, so check for that
                                            # now. Yet we also want to avoid
                                            # killing it while its in the middle
                                            # of triggering, and that can take
                                            # over 5mins when the db is heavily
                                            # loaded, so we rely on the redis
                                            # lock version of the job's heart
                                            # beat, which runs until the trigger
                                            # is over
                                            my $job = $sub->job;
                                            next if $job->locked;
                                            my $job_end = $job->end_time;
                                            if (!$job_end || time() > ($job_end->epoch + ($leeway * 3))) {
                                                $im->log("$dstr is currently running, but its claimed submission finished ages ago");
                                                $kill = 1;
                                            }
                                            else {
                                                next;
                                            }
                                        }
                                        #$im->debug("$dstr that sub isn't done yet");
                                        
                                        unless ($kill) {
                                            # if the job has started and is running, all
                                            # is well
                                            next if $sub->job->locked;
                                            #$im->debug("$dstr the job is dead or hasn't started yet");
                                            
                                            next if $sidtosub->time_since_assignment <= $leeway;
                                            $im->log("$dstr it's been over 5mins since assignment and the job (" . $sub->job->id . ") is dead or hasn't started yet");
                                        }
                                    }
                                }
                                else {
                                    # it hasn't grabbed a sub_id yet, but is
                                    # that because we don't need a handler for
                                    # this req_id anymore?
                                    my $req_id = $sidtosub->req_id;
                                    unless ($req_counts{$req_id}) {
                                        #$im->debug("$dstr it has not grabbed a sub_id because we no longer need a handler for req $req_id");
                                    }
                                    else {
                                        # ok, we still need it, perhaps it got
                                        # stuck? When the submission handler
                                        # undefs a submission it also updates
                                        # assignment time, so we can see how
                                        # long it has been sitting undefined
                                        next if $sidtosub->time_since_assignment <= $leeway;
                                        #$im->debug("$dstr it's been over 5mins since the handler tried to get a new submission");
                                    }
                                }
                                
                                #$im->debug("$dstr we'll ask the scheduler to kill this");
                                push(@sids_to_kill, [$sid, $aid]);
                            }
                            
                            # if we got this far it means either we're running
                            # with an assigned sub but aren't doing anything
                            # with it (we are stuck), or we're not running so
                            # must have exited
                            #$im->debug("$dstr we'll delete the sidtosub");
                            $sidtosub->delete;
                        }
                        
                        # kill anything running in the scheduler for which there
                        # has not been a sidtosub created for over 5 mins
                        foreach my $sid_aid (keys %running_in_scheduler) {
                            my ($sid, $aid) = $sid_aid =~ /(\d+)\[(\d+)/;
                            my $created = VRPipe::SidToSub->search({ farm => $farm, sid => $sid, aid => $aid });
                            unless ($created) {
                                my $run_time = $scheduler->run_time($sid, $aid);
                                if ($run_time > $leeway) {
                                    $im->log("we'll kill sid $sid\[$aid] because it never created a sidtosub");
                                    push(@sids_to_kill, [$sid, $aid]);
                                }
                            }
                        }
                        
                        # batch kill sids now
                        $scheduler->kill_sids(\@sids_to_kill);
                    }
                    
                    alarm 0;
                    return;
                }
                sub {
                    $still_working = 0;
                    my $err = $@;
                    if ($err) {
                        # perhaps another process decided our $farm_server was
                        # no longer alive and it has been deleted from the db?
                        # let's still keep the farmserver watcher alive so we
                        # will try and re-register as a farmserver - necessary
                        # when running a bunch of tests where the database keeps
                        # getting dropped and recreated while the server is
                        # running
                        if ($err =~ /^farmserver/) {
                            chomp($err);
                            $im->log("Could not continue submission management for farm $farm because $err.", email_admin => 1);
                            $farm_server->unlock;
                            undef $farm_server;
                        }
                        &{$watcher_error_sub};
                    }
                };
            }
        };
    }
    
    # set up the http page requests we'll respond to
    $backend->register_psgi_pages(
        '/' => sub {
            $backend->psgi_text_response(200, 'html', "<html><body><h1>VRPipe Homepage</h1>" . q[<p>Complete web interface to VRPipe coming soon; currently you can just look at the <a href="/status?brief=1&amp;incomplete=1">status</a> page (like the vrpipe-status command line script).</p>] . "</body></html>", shift);
        },
        '/status' => sub { $backend->psgi_nonblocking_xml_response(\&status, shift); },
        '/dsn'    => sub {
            $backend->psgi_text_response(200, 'plain', $backend->dsn, shift);
        },
        '/stop' => sub {
            shutdown_server("Received the stop command");
            $backend->psgi_text_response(200, 'plain', 'Stopping server', shift);
        }
    );
    
    # set up the signals we'll react to
    $SIG{HUP}  = 'IGNORE';
    $SIG{PIPE} = 'IGNORE';
    my $sigterm_watcher = EV::signal 'TERM', sub { shutdown_server("SIGTERM received"); };
    my $sigint_watcher  = EV::signal 'INT',  sub { shutdown_server("SIGINT received"); };
    my $sigquit_watcher = EV::signal 'QUIT', sub { shutdown_server("SIGQUIT received"); };
    
    # run the event loop
    $im->log("The $deployment server at $url for VRPipe database " . $backend->dsn . " has started for farm $farm (pid $$).", email_admin => 1, subject => 'The VRPipe Server is alive!') if $farm;
    EV::run;
    
    # cleanup handlers when testing (but not in production, since handlers
    # should keep running if the server goes down)
    eval {
        if ($farm_server) {
            $farm_server->unlock;
            $farm_server->delete;
        }
    };
    if ($deployment eq 'testing') {
        # make sure all our handlers have exited ***... I don't know of a good
        # way to ensure this; let's just wait 6 seconds and hope they commit
        # suicide now that the farmserver is gone
        sleep(6);
        
        # some schedulers may need to do something when the test server exits
        my $sch_on_exit_method = $scheduler ? $scheduler->on_exit_method : undef;
        if ($sch_on_exit_method) {
            $scheduler->scheduler_instance->$sch_on_exit_method;
        }
        
        # flush any remaining redis stderr to file
        &$im_stderr_output_sub() if $im_stderr_output_sub;
        
        # now we can get rid of the redis server
        $im->terminate_datastore;
    }
    
    $im->log("The $deployment server at $url for VRPipe database " . $backend->dsn . " ($farm farm) is exiting!", email_admin => 1, subject => 'The VRPipe Server is dead!') if $farm;
    exit 0;
}

sub shutdown_server {
    my $msg = shift;
    $im->log($msg . ", will gracefully shut down server.");
    EV::unloop;
}

sub _get_steplimit {
    my ($step, $step_limits, $completed_setups, $step_counts) = @_;
    my $step_id = $step->id;
    
    my $step_limit;
    if (exists $step_limits->{$step_id}) {
        $step_limit = $step_limits->{$step_id};
    }
    else {
        # figure out what the step limit is, if any,
        # by checking the config of every incomplete
        # & active setup that uses the step
        my @setups = VRPipe::PipelineSetup->search({ active => 1, 'step.id' => $step_id }, { join => { 'pipeline' => { 'stepmembers' => 'step' } } });
        if (@setups) {
            my $step_name = $step->name;
            foreach my $setup (@setups) {
                unless (exists $completed_setups->{ $setup->id }) {
                    $completed_setups->{ $setup->id } = $setup->currently_complete;
                }
                next if $completed_setups->{ $setup->id };
                my $setup_limit = $setup->options->{ $step_name . '_max_simultaneous' } || next;
                if (!defined $step_limit || $setup_limit < $step_limit) {
                    $step_limit = $setup_limit;
                }
            }
        }
        if (!defined $step_limit) {
            # also check the step itself for a limit
            $step_limit = $step->max_simultaneous;
        }
        $step_limits->{$step_id} = $step_limit || 0;
        
        if ($step_limit) {
            # see how many of this step are currently
            # running, globally
            my $pager = VRPipe::Submission->search_paged({ 'stepmember.step' => $step_id, '_done' => 0, '_failed' => 0 }, { join => { stepstate => 'stepmember' }, prefetch => 'job' });
            my $count = 0;
            while (my $subs = $pager->next) {
                foreach my $sub (@$subs) {
                    $count++ if $sub->job->locked;
                }
            }
            $step_counts->{$step_id} = $count;
        }
    }
    
    return $step_limit;
}

# "page" subs
sub status {
    my $req = shift;
    
    my $opts = $backend->req_to_opts($req, ['setup!PipelineSetup']);
    $opts->{'_multiple_setups'} = 1;
    my $list            = $opts->{list};
    my $incomplete_only = $opts->{incomplete};
    my $brief           = $opts->{brief};
    my $show_steps      = $brief ? 0 : $opts->{show_steps};
    my $defunct_only    = $opts->{defunct};
    my $gs              = $opts->{global_summary};
    if ($defunct_only) {
        undef $list;
        undef $incomplete_only;
        undef $brief;
        $opts->{deactivated} = 1;
    }
    my $deactivated = $opts->{deactivated} || 0;
    
    my $xml = '<title>Current status of PipelineSetups</title>';
    
    # $xml .= '<options><bool></bool></options>';
    
    my @setups = $backend->get_pipelinesetups($opts, $deactivated, $gs);
    
    if ($gs) {
        my $do_single_ps = (@setups && @setups == 1 && ($deactivated ? 1 : $setups[0]->active)) ? $setups[0]->id : 0;
        
        my $active                   = 0;
        my $incomplete               = 0;
        my $global_should_be_running = 0;
        my $global_actually_running  = 0;
        my $global_incomplete_des    = 0;
        my $global_working_des       = 0;
        my @lines;
        foreach my $setup (VRPipe::PipelineSetup->search({ $deactivated ? () : (active => 1) })) {
            $active++;
            unless ($setup->currently_complete) {
                $incomplete++;
                
                if ($do_single_ps) {
                    next unless $setup->id == $do_single_ps;
                }
                
                # do what the main --farm mode code does to decide what subs
                # to handle
                my $sub_pager = VRPipe::Submission->search_paged({ '_done' => 0, scheduler => $scheduler->id, 'pipelinesetup.controlling_farm' => $farm, 'pipelinesetup.id' => $setup->id, 'dataelement.withdrawn' => 0 }, { join => { stepstate => ['pipelinesetup', 'dataelement'] }, prefetch => ['job', { stepstate => { stepmember => 'step' } }] });
                
                my (%step_limits, %step_counts, %completed_setups);
                my $sub_count                     = 0;
                my $skipped_due_to_failed         = 0;
                my $skipped_due_to_block_and_skip = 0;
                my $skipped_due_to_step_limit     = 0;
                my $should_be_running             = 0;
                my $actually_running              = 0;
                while (my $subs = $sub_pager->next(no_resetting => 1)) {
                    foreach my $sub (@$subs) {
                        $sub_count++;
                        
                        if ($sub->_failed && $sub->retries >= 3) {
                            $skipped_due_to_failed++;
                            next;
                        }
                        
                        my $job = $sub->job;
                        if ($job->block_and_skip_if_ok) {
                            my ($first_sub) = VRPipe::Submission->search({ 'job' => $job->id, '_done' => 0 }, { rows => 1, order_by => { -asc => 'id' } });
                            unless ($first_sub && $first_sub->id == $sub->id) {
                                $skipped_due_to_block_and_skip++;
                                next;
                            }
                        }
                        
                        # global step limit handling
                        my $step       = $sub->stepstate->stepmember->step;
                        my $step_id    = $step->id;
                        my $step_limit = _get_steplimit($step, \%step_limits, \%completed_setups, \%step_counts);
                        if ($step_limit && $step_counts{$step_id} >= $step_limits{$step_id}) {
                            $skipped_due_to_step_limit++;
                            next;
                        }
                        
                        $step_counts{$step_id}++;
                        $should_be_running++;
                        
                        if ($job->locked) {
                            $actually_running++;
                        }
                    }
                }
                $global_should_be_running += $should_be_running;
                $global_actually_running  += $actually_running;
                
                push(@lines, 'Setup ' . $setup->id . qq[ Submission status: incomplete=$sub_count; failed=$skipped_due_to_failed; blocking=$skipped_due_to_block_and_skip; limited=$skipped_due_to_step_limit; should be running=$should_be_running; actually running=$actually_running]);
                
                # do what the setups handler does to see if there are any
                # stalled (submissionless, incomplete) dataelementstates
                my $des_count      = VRPipe::DataElementState->search({ pipelinesetup => $setup->id, 'dataelement.withdrawn' => 0 }, { join => 'dataelement' });
                my $incomplete_des = 0;
                my $working_des    = 0;
                my $stalled_des    = 0;
                my $ie_pager       = $setup->datasource->incomplete_element_states($setup, prepare => 0);
                if ($ie_pager) {
                    while (my $dess = $ie_pager->next) {
                        foreach my $des (@$dess) {
                            $incomplete_des++;
                            my $have_subs = VRPipe::Submission->search({ 'stepstate.dataelement' => $des->dataelement->id, 'stepstate.pipelinesetup' => $setup->id }, { join => 'stepstate' });
                            
                            my $working = 1;
                            if ($have_subs) {
                                my $complete_subs = VRPipe::Submission->search({ 'stepstate.dataelement' => $des->dataelement->id, 'stepstate.pipelinesetup' => $setup->id, '_done' => 1 }, { join => 'stepstate' });
                                if ($complete_subs == $have_subs) {
                                    $working = 0;
                                }
                            }
                            else {
                                $working = 0;
                            }
                            
                            $working ? $working_des++ : $stalled_des++;
                        }
                    }
                }
                
                $global_incomplete_des += $incomplete_des;
                $global_working_des    += $working_des;
                
                push(@lines, 'Setup ' . $setup->id . qq[ DataElement status: total=$des_count; incomplete=$incomplete_des; working=$working_des; stalled=$stalled_des]);
            }
        }
        
        unless ($do_single_ps) {
            unshift(@lines, qq[All setups: incomplete submissions=$global_should_be_running; submissions actually running=$global_actually_running; incomplete dataelements=$global_incomplete_des; working dataelements=$global_working_des]);
        }
        unshift(@lines, 'Total active' . ($deactivated ? ' and deactivated' : '') . qq[ setups=$active; Total incomplete setups=$incomplete]);
        
        $xml .= join('', map { '<response_line>' . $_ . '</response_line>' } @lines);
        return $xml;
    }
    
    if (@setups) {
        my @objects;
        foreach my $setup (@setups) {
            my $object;
            foreach my $attr (qw(id name user active)) {
                $object .= $backend->xml_tag('attribute', $setup->$attr(), qq[name="$attr"]);
            }
            
            if ($list) {
                push(@objects, $object);
                next;
            }
            
            my $datasource = $setup->datasource;
            my $num_elements;
            my $incomplete_pager;
            my $ps_id = $setup->id;
            eval {
                $num_elements = VRPipe::DataElementState->search({ pipelinesetup => $setup->id, 'dataelement.datasource' => $datasource->id, 'dataelement.withdrawn' => 0 }, { join => 'dataelement' });
                $incomplete_pager = $datasource->incomplete_element_states($setup, prepare => 0);
            };
            my $ds_error = $@;
            if ($ds_error || !$incomplete_pager) {
                $ds_error ||= 'Could not create an incomplete_element_states pager for setup ' . $setup->id;
                if ($defunct_only) {
                    #*** due to prepare => 0 above, this will never happen, but
                    #    to prepare => 1 in $defunct_only mode would be too slow
                    my $prob = $ds_error ? 'a bad datasource' : 'no dataelements';
                    $object .= $backend->xml_tag('attribute', "This has $prob; investigate with [vrpipe-status --setup $ps_id] and consider deleting it with [vrpipe-setup --setup $ps_id --delete]", qq[name="problems"]);
                }
                else {
                    $object .= $backend->xml_tag('attribute', "There is a problem with the DataSource for this pipeline, so no more information can be retrieved about it.\n$ds_error\n", qq[name="problems"]);
                }
                push(@objects, $object);
                next;
            }
            
            my $num_incomplete = $incomplete_pager->total_entries;
            next if $incomplete_only && !$num_incomplete;
            
            if ($defunct_only) {
                if ($num_incomplete && $setup->active == 0) {
                    $object .= $backend->xml_tag('attribute', "This is inactive but has $num_incomplete incomplete dataelements; if this setup was started but then abandoned (due to an error setting it up, or it being replaced by another setup) consider deleting it with [vrpipe-setup --setup $ps_id --delete]", qq[name="problems"]);
                    push(@objects, $object);
                }
                next;
            }
            
            my $pipeline     = $setup->pipeline;
            my $step_members = $pipeline->step_members;
            unless ($brief) {
                # pipeline details
                $object .= '<attribute name="pipeline"><object class="Pipeline" display_mode="full">';
                foreach my $attr (qw(id name description)) {
                    $object .= $backend->xml_tag('attribute', $pipeline->$attr(), qq[name="$attr"]);
                }
                $object .= $backend->xml_tag('attribute', $step_members, q[name="num_steps"]);
                $object .= '</object></attribute>';
                
                if ($show_steps) {
                    # pipeline step details
                    $object .= '<attribute name="steps">';
                    my (%steps, @step_order);
                    foreach my $sm ($pipeline->step_members) {
                        my $step_num = $sm->step_number;
                        my $step     = $sm->step;
                        my $name     = $step->name;
                        my $inputs   = join(', ', keys %{ $step->inputs_definition || {} }) || '';
                        my $outputs  = join(', ', keys %{ $step->outputs_definition || {} }) || '';
                        my $step_id  = "$step_num.$name";
                        $steps{$step_id} = "Description: " . $step->description . "; Inputs: $inputs; Outputs: $outputs";
                        push(@step_order, $step_id);
                    }
                    $object .= $backend->hash_to_xml(\%steps, \@step_order);
                    $object .= '</attribute>';
                }
                
                # setup options and output root
                my $ps_opts = $setup->options;
                $object .= '<attribute name="options">';
                if (keys %$ps_opts) {
                    $object .= $backend->hash_to_xml($ps_opts);
                }
                else {
                    $object .= '(used with default/no options)';
                }
                $object .= '</attribute>';
                $object .= $backend->xml_tag('attribute', $setup->output_root->stringify, q[name="output_root"]);
                $object .= $backend->xml_tag('attribute', $setup->unix_group || 'default', q[name="unix_group"]);
                
                # datasource details
                $object .= '<attribute name="datasource"><object class="DataSource" display_mode="full">';
                foreach my $attr (qw(id type method source)) {
                    $object .= $backend->xml_tag('attribute', $datasource->$attr(), qq[name="$attr"]);
                }
                my $ds_opts = $datasource->options;
                $object .= '<attribute name="options">';
                if (keys %$ds_opts) {
                    $object .= $backend->hash_to_xml($ds_opts);
                }
                else {
                    $object .= '(used with default/no options)';
                }
                $object .= '</attribute>';
                $object .= '</object></attribute>';
            }
            
            $object .= $backend->xml_tag('attribute', $num_elements,   q[name="elements_total"]);
            $object .= $backend->xml_tag('attribute', $num_incomplete, q[name="elements_incomplete"]);
            if ($num_incomplete) {
                my %status_hash;
                my $fully_complete = $num_elements - $num_incomplete;
                $status_hash{$step_members} = $fully_complete;
                my $num_steps_complete = $fully_complete * $step_members;
                while (my $incompletes = $incomplete_pager->next) {
                    foreach my $es (@$incompletes) {
                        my $completed_steps = $es->completed_steps;
                        $num_steps_complete += $completed_steps;
                        $status_hash{$completed_steps}++;
                    }
                }
                $object .= '<attribute name="steps_completed">' . $backend->hash_to_xml(\%status_hash, [sort { my ($ay) = $a =~ /^(\d+)/; my ($be) = $b =~ /^(\d+)/; $ay <=> $be } keys %status_hash]) . '</attribute>';
                
                my $steps_to_complete = $num_elements * $step_members;
                my $percent_complete = sprintf("%0.2f", (100 / $steps_to_complete) * $num_steps_complete);
                $object .= $backend->xml_tag('attribute', "$percent_complete\%", qq[name="completion" explanation="Pipeline currently $percent_complete\% complete ($num_steps_complete / $steps_to_complete steps completed)"]);
                
                my $farm = $setup->controlling_farm;
                if ($farm) {
                    my ($farm_server) = VRPipe::FarmServer->search({ farm => $farm });
                    if (!$farm_server || !$farm_server->locked) {
                        $object .= $backend->xml_tag('attribute', "WARNING! setup may be stalled because it is being controlled by the VRPipe server for farm $farm, but no server for that farm is currently alive", q[name="problems"]);
                    }
                }
                
                my $pager = VRPipe::Submission->search_paged({ "_done" => 0, 'stepstate.pipelinesetup' => $setup->id, 'dataelement.withdrawn' => 0 }, { join => { 'stepstate' => 'dataelement' }, prefetch => 'job' });
                my %sub_stats;
                while (my $subs = $pager->next(no_resetting => 1)) {
                    foreach my $sub (@$subs) {
                        next if $sub->done;
                        my $sub_state = $sub->failed ? 'failed' : 'scheduled';
                        if ($sub_state eq 'scheduled') {
                            my $job = $sub->job;
                            $sub_state = $job->end_time ? 'processing' : ($job->locked ? 'running' : 'pending');
                        }
                        $sub_stats{$sub_state}++;
                    }
                }
                if (keys %sub_stats) {
                    $object .= '<attribute name="submission_state">' . $backend->hash_to_xml(\%sub_stats, [qw(running processing pending failed)]) . '</attribute>';
                    if (keys %sub_stats == 1 && exists $sub_stats{failed}) {
                        my $failed = $sub_stats{failed};
                        if ($failed >= $num_incomplete) {
                            $object .= $backend->xml_tag('attribute', "WARNING! It looks like this setup may be STALLED due to repeated failures.\nInvestigate using: vrpipe-submissions --setup " . $setup->id . " --failed", q[name="problems"]);
                        }
                    }
                }
                else {
                    # well, what is happening to this setup then? probably we
                    # have the same submissions as some other setup
                    $incomplete_pager = $datasource->incomplete_element_states($setup, prepare => 0);
                    my @step_members  = $pipeline->step_members;
                    my $found_problem = 0;
                    ESCHECKER: while (my $incompletes = $incomplete_pager->next) {
                        foreach my $es (@$incompletes) {
                            my $element         = $es->dataelement;
                            my $completed_steps = $es->completed_steps;
                            next if $completed_steps == $step_members;
                            
                            foreach my $member (@step_members) {
                                my $step_number = $member->step_number;
                                my ($state) = VRPipe::StepState->search({
                                        stepmember    => $member,
                                        dataelement   => $element,
                                        pipelinesetup => $setup
                                    }
                                );
                                next unless $state;
                                next if $state->complete;
                                
                                my @submissions = $state->submissions;
                                if (@submissions) {
                                    my $other_state = $state->same_submissions_as;
                                    if ($other_state) {
                                        my $other_setup = $other_state->pipelinesetup->id;
                                        if ($other_setup != $setup->id && $other_state->complete != 1) {
                                            $object .= $backend->xml_tag('attribute', "Note: this setup is dependent on work being done by setup $other_setup, so check the status of that to see what's happening.");
                                            $found_problem = 1;
                                            last ESCHECKER;
                                        }
                                    }
                                }
                                else {
                                    $object .= $backend->xml_tag('attribute', "Note: currently processing step $step_number (" . $member->step->name . ").\nIt's possible something has gone wrong with this step and the setup is stalled; you should have received an email with further details in that case.");
                                    $found_problem = 1;
                                    last ESCHECKER;
                                }
                            }
                        }
                    }
                    
                    $object .= $backend->xml_tag('attribute', "Note: the setup hasn't completed but there are no submissions for it and I can't detect obvious problems; maybe it's in the middle of processing and something will happen soon.") unless $found_problem;
                }
            }
            else {
                if ($num_elements == 0) {
                    $object .= '<attribute name="completion" explanation="Pipeline has no inputs to work on (yet?), so has done nothing.">n/a</attribute>';
                }
                else {
                    $object .= '<attribute name="completion" explanation="Pipeline currently 100% complete!">100%</attribute>';
                }
            }
            
            push(@objects, $object);
        }
        
        if (@objects) {
            my $mode = $list ? 'list' : ($brief ? 'brief' : ($defunct_only ? 'defunct' : 'full'));
            $xml .= '<objects>' . join('', map { qq[<object class="PipelineSetup" display_mode="$mode">] . $_ . '</object>' } @objects) . '</objects>';
        }
    }
    
    return $xml;
}
